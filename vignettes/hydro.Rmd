---
title: "Hydrology"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Hydrology}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
## Setting up the R environment
  
The first thing to do is to load all of the packages we need to use for this tutorial:
  
```{r error=TRUE,message=FALSE,warning=FALSE}
library(leaflet)
library(jsonlite)
library(ggplot2)
library(inlabru)
library(INLA)
library(rgdal)
library(raster)
library(ncdf4)
library(data.table)
```

If you do not have `INLA` or `inlabru` installed [please go to the following installation tutorial before continuing](link%20to%20installation%20tutorial).

First we'll download the data for this tutorial from our [data repository](https://github.com/4DModeller/fdmr_data) using `retrieve_tutorial_data`.

```{r error=TRUE,message=FALSE,warning=FALSE}
fdmr::retrieve_tutorial_data(dataset = "hydro")
```

Next we'll use `get_tutorial_datapath` to get the path to the data files.

```{r}
norway_polygon_location <- fdmr::get_tutorial_datapath(filename = "Kvilldal_Catch_Boundary.geojson")
streamdata_13 <- fdmr::get_tutorial_datapath(filename = "NVEobservations_s36_13.csv")
streamdata_14 <- fdmr::get_tutorial_datapath(filename = "NVEobservations_s36_14.csv")
era5_location <- fdmr::get_tutorial_datapath(filename = "era5_land_daily.nc")
```

## Kvilldal dam area

First we will look at the location of the dam by making a map and plotting the stream gauges on it.

```{r error=TRUE,warning=FALSE}
# TODO : here is a good example for the map function
norway_polygon <- rgdal::readOGR(norway_polygon_location)
norway_polygon <- sf::st_as_sf(norway_polygon
                               , coords=c("longitude", "latitude")
                               , crs="+proj=utm +zone=32")

suldalsvatnet_dam <- list(longitude=6.517174, latitude=59.490720, name="Suldalsvatnet Dam")
stream_gauge_13 <- list(longitude=6.5395789, latitude=59.5815849, name="Stream Gauge 13")
stream_gauge_14 <- list(longitude=6.7897968, latitude=59.7531662, name="Stream Gauge 14")


sfc <- sf::st_transform(norway_polygon, crs = "+proj=longlat +datum=WGS84")

leaflet(sfc, height = 500, width = 750) %>%
  addTiles() %>%
  addPolygons(stroke = FALSE, smoothFactor = 0.3,
              fillColor = "red",
              fillOpacity = 0.5) %>%
  addTiles("https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}",
           attribution = 'Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community') %>%
  addMarkers(lat=suldalsvatnet_dam$latitude, lng=suldalsvatnet_dam$longitude, popup=suldalsvatnet_dam$name) %>%
  addMarkers(lat=stream_gauge_13$latitude, lng=stream_gauge_13$longitude, popup=stream_gauge_13$name) %>%
  addMarkers(lat=stream_gauge_14$latitude, lng=stream_gauge_14$longitude, popup=stream_gauge_14$name)
```

On the map you can see the dam, the resevoir, the catchment area, and the two stream gauges.

The area inside the shape is where water accumulates, the area outside of the boundary has water that goes elsewhere. This will be important later when we are including ERA5-land precipitation data. 

## Stream gauge data

The stream gauge data is measured as the average daily liters/second that pass through the area. This data goes back for many years, sometimes decades. See below:
  
```{r error=TRUE, fig.align='center', fig.width=7}
data_13 <- read.csv(streamdata_13)
data_13$date <- as.Date(data_13$time)
data_13 <- subset(data_13, date >= "2021-10-01" & date <= "2021-10-31")
row.names(data_13) <- NULL
data_13$time_index <- seq(1, 31, 1)

data_14 <- read.csv(streamdata_14)
data_14$date <- as.Date(data_14$time)
data_14 <- subset(data_14, date >= "2021-10-01" & date <= "2021-10-31")
row.names(data_14) <- NULL
data_14$time_index <- seq(1, 31, 1)

# Create a line plot using ggplot2
ggplot(data_13, aes(x = as.Date(time), y = value)) +
  geom_line(color = "violet") +
  labs(x = "Time", y = "Stream Flow : Daily Average (Liter/s)")
ggplot(data_14, aes(x = as.Date(time), y = value)) +
  geom_line(color = "limegreen") +
  labs(x = "Time", y = "Stream Flow : Daily Average (Liter/s)")

# we rescale the data with the zscore since hte values are so
# different between the two stream gauges
data_13$value <- scale(data_13$value)
data_14$value <- scale(data_14$value)
```

You can see, these two different stream gauges record a very different amount of stream flow. Therefore we should likely normalize this data using the zscore


The response variable in this study is the stream flow measurement. The amount of water that passes through the stream gauge is representative of the amount of water that will accumulate in the resevoir. Thus, in order to understand how this changes over time, it will be important to understand what physical processes drive water into the streams that feed the resevoir.

## ERA5-land data

[ERA5-land data includes many variables](https://www.ecmwf.int/en/era5-land). Here we use only the daily precipitation data. [ERA5-land precipitation](https://codes.ecmwf.int/grib/param-db/?id=228) comes from reanalysis of the climate model.

ERA5-land data is gridded however we need the data to be assigned to catchment shapes.

```{r error = TRUE,warning=FALSE}
# TODO : mapping function here too

era5_precip <- raster::stack(era5_location)
era5_precip %>% raster::values() %>% raster::hist(main="Total Precipitation", col="violet")

sr <- "+proj=utm +zone=32"
projected_raster <- raster::projectRaster(era5_precip, crs = sr)

crop_era5 <- raster::mask(projected_raster, norway_polygon)
crop_era5 <- terra::crop(crop_era5, raster::extent(norway_polygon), snap="near")

leaflet::leaflet(sfc, width=750, height=500) %>% 
  leaflet::addTiles() %>%
  leaflet::addRasterImage(x = crop_era5$X2021.10.01, 
                 opacity = 1) %>%
  leaflet::addPolygons(stroke = FALSE, smoothFactor = 0.3,
              fillColor = "red",
              fillOpacity = 0.5)
```

Create a data frame rsdf containing precipitation data

```{r error=TRUE}
rsdf <- data.frame(rasterToPoints(crop_era5))
rsdf <- melt(setDT(rsdf), id.vars=c("x","y"), variable.name = "time")
rsdf$time <- sapply(rsdf$time, function(t) {
  as.integer(strsplit(as.character(t), '\\.')[[1]][3])
})
rsdf <- setNames(rsdf, c('x', 'y', 'time', 'precip'))
```


We need to figure out which ERA5 precipitation pixels are closest to which stream gauge so we can match the data for the regression. First we need to calculate the distance between the pixel and each stream gauge, then use the minimum distance to choose the stream gauge. We first create a function that converts latlong to utm coordinate reference system


```{r error=TRUE, latlong2utm}
# TODO : this needs to be moved to 4dm
latlong_to_utm <- function(lat, lon) {
  
  # Create a spatial points object with input coordinates
  input_point <- SpatialPoints(matrix(c(lon, lat), ncol = 2), proj4string = CRS("+proj=longlat +datum=WGS84"))
  
  # Define the UTM zone number and hemisphere for the output coordinate system
  utm_zone <- as.character((floor((lon + 180)/6) %% 60) + 1)
  utm_hemisphere <- ifelse(lat < 0, "S", "N")
  utm_proj_string <- paste0("+proj=utm +zone=", utm_zone, " +", utm_hemisphere)
  
  # Convert the input point to the output coordinate system
  output_point <- spTransform(input_point, CRS(utm_proj_string))
  
  # Return the UTM coordinates as a vector
  return(c(output_point@coords[,1], output_point@coords[,2]))
}

```

Now we can match the pixel precipation data to the nearest stream gauge.

```{r error=TRUE, matchpixel}
pixel_coords <- unique(sp::coordinates(crop_era5))
s13_utm <- latlong_to_utm(lat=stream_gauge_13$latitude
                          ,lon=stream_gauge_13$longitude)
s14_utm <- latlong_to_utm(lat=stream_gauge_14$latitude
                          ,lon=stream_gauge_14$longitude)

s13 <- data.frame(x=s13_utm[[1]], y=s13_utm[[2]])
s14 <- data.frame(x=s14_utm[[1]], y=s14_utm[[2]])
pixel_dist_gauge<-data.frame(x=pixel_coords[,1],
                             y=pixel_coords[,2],
                             dist_s1=rep(NA,nrow(pixel_coords)),
                             dist_s2=rep(NA,nrow(pixel_coords)),
                             min_s=rep(NA,nrow(pixel_coords)),
                             streamflow=rep(NA, nrow(pixel_coords))
)
for (i in 1:nrow(pixel_coords)){
  pixel_dist_gauge$dist_s1[i]<-sqrt((pixel_dist_gauge$x[i]-s13$x)^2+
                                      (pixel_dist_gauge$y[i]-s13$y)^2)
  
  pixel_dist_gauge$dist_s2[i]<-sqrt((pixel_dist_gauge$x[i]-s14$x)^2+
                                      (pixel_dist_gauge$y[i]-s14$y)^2)
  pixel_dist_gauge$min_s[i]<-which.min(c(pixel_dist_gauge$dist_s1[i],
                                         pixel_dist_gauge$dist_s2[i]))
}


# the dataframe pixel_dist_gauge then needs to be replicated by the number of time points 
n.time <- nlayers(era5_precip)
pixel_dist_gauge<-do.call(rbind, replicate(n.time, pixel_dist_gauge, simplify=FALSE))
pixel_dist_gauge$time<-rep(1:n.time,each=nrow(pixel_coords))

streamdata <- list(data_13, data_14)
get_stream_data <- function(row) {
  which_stream_data <- streamdata[[row['min_s']]]
  data_at_row_time_index <- which_stream_data[which_stream_data[,c("time_index")] == row['time'],]
  return(data_at_row_time_index$value)
}
pixel_dist_gauge$streamflow <- apply(pixel_dist_gauge,1,get_stream_data)

```


Now we create a new SpatialPointDataFrame inla_data for model fitting. The data frame contains the response and predictor data at each spatial location and time point.

```{r error=TRUE,inladat}
inla_data<-merge(pixel_dist_gauge,rsdf,by=c("time","x","y"))
inla_data <- subset(inla_data, select=c('x', 'y', 'streamflow', 'precip', 'time'))
sp::coordinates(inla_data)<- c("x","y")

head(inla_data@data)
head(inla_data@coords)
```


# Creating the BHM using 4D-Modeller

In order to model this with the 4D-Modeller we need to:
  
1.  create a spacial mesh which the SPDE model can be evaluated over
2.  build the SPDE model
3.  Define how the process evolves over time

## mesh resolution

Create the triangulated mesh of the study region

```{r error=TRUE,warning=FALSE, fig.width=7, fig.height=7}
# TODO : it would be nice to map the mesh onto the dataset using the mapmaker function i am suggesting
e <- crop_era5@extent
resolution <- res(crop_era5)
xres <- resolution[1]*2
yres <- resolution[2]*2
xy <- sp::coordinates(crop_era5)

# maybe this makes the mesh smaller lol
xy <- xy[seq(1, nrow(xy), by = 2), ]
# mesh <- INLA::inla.mesh.2d(loc=xy, max.edge=c(xres*1000, xres*10000), cutoff=2000, crs=sr)
# mesh <- INLA::inla.mesh.2d(loc=xy, max.edge=c(xres*1, xres*100), cutoff=2000, crs=sr)
mesh <- INLA::inla.mesh.2d(loc=xy, max.edge=c(xres*1, xres*100), cutoff=75, crs=sr)
plot(mesh)

```

## priors

the priors here are describing how the unobserved variannce is distributed over the region. That is, how far away from the center of the process should it cease to spatially correlate with the surrounding environment. To put it a different way, if it is raining on a hill top, how far from that hill must you be to not notice if it's raining or not.

In this case, we set the prior range to be 20km.

```{r error=TRUE, spde}

# prior.range<-0.296
# the prior range is the distance that the process should stop effecting, so in this case it is currently 20km away from the node center
prior.range<-20.0
spde <- inla.spde2.pcmatern(
  mesh = mesh, 
  prior.range = c(prior.range, 0.5), 
  prior.sigma = c(1, 0.01) 
)

```

the model has some time dependency.

```{r pccor}
rhoprior <- base::list(theta = list(prior = 'pccor1', param = c(0, 0.9)))
```

In order to fit the model, we also need to define a temporal index and the number of discrete time points we want to model. The INLA model requires that time indicies must be an integer starting at 1.

```{r error=TRUE}
group.index <- inla_data@data$time 
n_groups<-length(unique(group.index))

```


## Model Inference

The model below predicts the streamflow given the precipitation as a fixed effect and an SPDE model which assumes there is some other correlation structure in the streamflow data due to unobserved variables. Likely unobserved co-variates could be local elevation, temperature, soil permeability, or presence of vegetation.

```{r error=TRUE}
formula1 <- streamflow ~ 0 + Intercept + precip

formula2 <- streamflow ~ 0 + Intercept + precip +
  f(main=coordinates,
    model=spde,
    group=group.index,
    ngroup=n_groups,
    control.group=list(model="ar1",
                       hyper=rhoprior))
```



```{r error=TRUE, modelrun}
inlabru.model1 <- bru(formula1, data = inla_data,
                   family = "gaussian",
                   options = list(
                     verbose = TRUE
                   )
)

inlabru.model2 <- bru(formula2, data = inla_data,
                   family = "gaussian",
                   options = list(
                     verbose = TRUE
                   )
)
```

now its time to see its output

```{r error=TRUE}
# TODO : this could be where the model_eval function i recommend could be used
summary(inlabru.model1)
```
```{r error=TRUE}
summary(inlabru.model2)
```
