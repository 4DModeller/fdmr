[{"path":"https://4dmodeller.github.io/fdmr/CHANGELOG.html","id":null,"dir":"","previous_headings":"","what":"Changelog","title":"Changelog","text":"notable changes fdmr documented file. format based Keep Changelog, project adheres Semantic Versioning.","code":""},{"path":[]},{"path":"https://4dmodeller.github.io/fdmr/CHANGELOG.html","id":"added","dir":"","previous_headings":"[Unreleased]","what":"Added","title":"Changelog","text":"changelog - PR #99","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://4dmodeller.github.io/fdmr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"fixed-effects","dir":"Articles","previous_headings":"","what":"Fixed Effects","title":"How to choose how to model","text":"fixed effect bayesian model effect whose value fixed location probability distribution associated ’s uncertainty. fixed effect represents parameter coefficient model assumed fixed, constant value across different observations/locations. Bayesian model, fixed effect special case random effect assume effect zero variance.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"why-would-you-choose-a-fixed-effect","dir":"Articles","previous_headings":"Fixed Effects","what":"why would you choose a fixed effect?","title":"How to choose how to model","text":"choose model effect fixed effect believe effect always outcome matter context observation taken. example, unit rain fill reservoir equivalent unit matter conditions given constant climatic conditions non-porous soil.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"example-of-a-fixed-effect-in-r-inlainlabru","dir":"Articles","previous_headings":"Fixed Effects","what":"example of a fixed effect in r-inla/inlabru","title":"How to choose how to model","text":"fixed effect represented fit equation variable name. simulated data example, three columns x, y, time. can see written formula passed inla.","code":"formula <- value ~ 1 + x + y + time result <- inla(formula, data = df, family = \"gaussian\") summary(result) ##  ## Call: ##    c(\"inla.core(formula = formula, family = family, contrasts = contrasts,  ##    \", \" data = data, quantiles = quantiles, E = E, offset = offset, \", \"  ##    scale = scale, weights = weights, Ntrials = Ntrials, strata = strata,  ##    \", \" lp.scale = lp.scale, link.covariates = link.covariates, verbose =  ##    verbose, \", \" lincomb = lincomb, selection = selection, control.compute  ##    = control.compute, \", \" control.predictor = control.predictor,  ##    control.family = control.family, \", \" control.inla = control.inla,  ##    control.fixed = control.fixed, \", \" control.mode = control.mode,  ##    control.expert = control.expert, \", \" control.hazard = control.hazard,  ##    control.lincomb = control.lincomb, \", \" control.update =  ##    control.update, control.lp.scale = control.lp.scale, \", \"  ##    control.pardiso = control.pardiso, only.hyperparam = only.hyperparam,  ##    \", \" inla.call = inla.call, inla.arg = inla.arg, num.threads =  ##    num.threads, \", \" keep = keep, working.directory = working.directory,  ##    silent = silent, \", \" inla.mode = inla.mode, safe = FALSE, debug =  ##    debug, .parent.frame = .parent.frame)\" )  ## Time used: ##     Pre = 0.511, Running = 0.249, Post = 0.0227, Total = 0.783  ## Fixed effects: ##               mean    sd 0.025quant 0.5quant 0.975quant   mode kld ## (Intercept) -0.301 0.108     -0.514   -0.301     -0.088 -0.301   0 ## x            0.010 0.011     -0.011    0.010      0.031  0.010   0 ## y           -0.002 0.011     -0.023   -0.002      0.019 -0.002   0 ## time        -0.013 0.011     -0.034   -0.013      0.008 -0.013   0 ##  ## Model hyperparameters: ##                                         mean    sd 0.025quant 0.5quant ## Precision for the Gaussian observations 1.02 0.046      0.934     1.02 ##                                         0.975quant mode ## Precision for the Gaussian observations       1.11 1.02 ##  ## Marginal log-Likelihood:  -1445.73  ##  is computed  ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"random-effects","dir":"Articles","previous_headings":"","what":"Random Effects","title":"How to choose how to model","text":"random effect bayesian model effect whose value drawn probability distribution associated uncertainty drawn ’s distribution. two types random effects can modeled inla, random effects unobserved processes random effects constrained observed processes.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"random-effects-of-unobserved-processes","dir":"Articles","previous_headings":"Random Effects","what":"Random Effects of Unobserved Processes","title":"How to choose how to model","text":"Unobserved processes processes may spatially temporally distributed data theoretical description might . Instead, considered variance found within data representative randomness instead kind unobserved process. example, patients infected COVID-19 impacted social demographic factors helped control infection rates link. addition social demographic factors, unobserved migration people neighborhood thereby increasing total number potential people infected? create unobserved variance data set (assuming neighborhood population counts). show model defines formula f subroutine represents unobserved variance occuring time x y fixed effects.gi","code":"# Define a formula for the model # Load the INLA library  # Define the formula for the INLA model formula <- value ~ 1 + x + y + f(time, model = \"rw1\")  # Fit the INLA model result <- inla(formula, data = df, family = \"gaussian\")  # Print the summary of the INLA model summary(result) ##  ## Call: ##    c(\"inla.core(formula = formula, family = family, contrasts = contrasts,  ##    \", \" data = data, quantiles = quantiles, E = E, offset = offset, \", \"  ##    scale = scale, weights = weights, Ntrials = Ntrials, strata = strata,  ##    \", \" lp.scale = lp.scale, link.covariates = link.covariates, verbose =  ##    verbose, \", \" lincomb = lincomb, selection = selection, control.compute  ##    = control.compute, \", \" control.predictor = control.predictor,  ##    control.family = control.family, \", \" control.inla = control.inla,  ##    control.fixed = control.fixed, \", \" control.mode = control.mode,  ##    control.expert = control.expert, \", \" control.hazard = control.hazard,  ##    control.lincomb = control.lincomb, \", \" control.update =  ##    control.update, control.lp.scale = control.lp.scale, \", \"  ##    control.pardiso = control.pardiso, only.hyperparam = only.hyperparam,  ##    \", \" inla.call = inla.call, inla.arg = inla.arg, num.threads =  ##    num.threads, \", \" keep = keep, working.directory = working.directory,  ##    silent = silent, \", \" inla.mode = inla.mode, safe = FALSE, debug =  ##    debug, .parent.frame = .parent.frame)\" )  ## Time used: ##     Pre = 0.314, Running = 0.28, Post = 0.0165, Total = 0.611  ## Fixed effects: ##               mean    sd 0.025quant 0.5quant 0.975quant   mode kld ## (Intercept) -0.372 0.065     -0.499   -0.372     -0.245 -0.372   0 ## x            0.010 0.008     -0.005    0.010      0.025  0.010   0 ## y           -0.002 0.008     -0.017   -0.002      0.013 -0.002   0 ##  ## Random effects: ##   Name     Model ##     time RW1 model ##  ## Model hyperparameters: ##                                         mean   sd 0.025quant 0.5quant ## Precision for the Gaussian observations 2.00 0.09      1.826     2.00 ## Precision for time                      1.25 0.55      0.466     1.15 ##                                         0.975quant  mode ## Precision for the Gaussian observations       2.18 1.993 ## Precision for time                            2.58 0.966 ##  ## Marginal log-Likelihood:  -1137.10  ##  is computed  ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"random-effects-constrained-by-observed-processes","dir":"Articles","previous_headings":"Random Effects","what":"Random Effects Constrained by Observed Processes","title":"How to choose how to model","text":"Observed data can used constrain effects inla/inlabru can used data driven inversion, .e., estimating processes observed directly. example,","code":"library(inlabru) ## Loading required package: fmesher ##  ## Attaching package: 'inlabru' ## The following object is masked from 'package:MASS': ##  ##     shrimp # Fit a simple model fit <- bru(value ~ 1 + observed(x + y, model = \"linear\"), data = df)  # Print the model summary print(summary(fit)) ## inlabru version: 2.9.0 ## INLA version: 23.09.09 ## Components: ## observed: main = linear(x + y), group = exchangeable(1L), replicate = iid(1L) ## Intercept: main = linear(1), group = exchangeable(1L), replicate = iid(1L) ## Likelihoods: ##   Family: 'gaussian' ##     Data class: 'data.frame' ##     Predictor: value ~ . ## Time used: ##     Pre = 0.298, Running = 0.255, Post = 0.102, Total = 0.655  ## Fixed effects: ##             mean    sd 0.025quant 0.5quant 0.975quant   mode kld ## observed   0.004 0.008     -0.011    0.004      0.019  0.004   0 ## Intercept -0.372 0.090     -0.549   -0.372     -0.194 -0.372   0 ##  ## Model hyperparameters: ##                                         mean    sd 0.025quant 0.5quant ## Precision for the Gaussian observations 1.02 0.046      0.934     1.02 ##                                         0.975quant mode ## Precision for the Gaussian observations       1.11 1.02 ##  ## Deviance Information Criterion (DIC) ...............: 2822.37 ## Deviance Information Criterion (DIC, saturated) ....: 1005.42 ## Effective number of parameters .....................: 2.99 ##  ## Watanabe-Akaike information criterion (WAIC) ...: 2822.56 ## Effective number of parameters .................: 3.17 ##  ## Marginal log-Likelihood:  -1435.50  ##  is computed  ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://4dmodeller.github.io/fdmr/articles/DecisionTree.html","id":"comparing-the-output","dir":"Articles","previous_headings":"Random Effects","what":"Comparing the output","title":"How to choose how to model","text":"Finally, can compare output models using DIC. important like know fittedness model even theoretical belief model specificied certain way.","code":"plot(DICs) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'DICs' not found"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"modelling-covid-19-infection-across-england","dir":"Articles","previous_headings":"","what":"Modelling COVID-19 infection across England","title":"COVID-19","text":"tutorial ’ll cover work part study fitting Bayesian spatio-temporal model predict COVID-19 infection rate across England.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"study-aim-and-data-description","dir":"Articles","previous_headings":"","what":"Study aim and data description","title":"COVID-19","text":"COVID-19 pandemic profound impact global health economies, spread evolution virus becoming major concern health authorities policymakers. study, aim investigate spread evolution COVID-19 occurrences across England. aim study two-fold: one hand, fitting Bayesian spatio-temporal model predict COVID-19 infection rate across mainland England space time; hand, investigating impacts socioeconomic, demographic environmental factors COVID-19 infection. first thing load packages used COVID-19 case study. study region mainland England, partitioned 6789 neighbourhoods Middle Layer Super Output Area (MSOA) scale. shapefile study region shape SpatialPolygonsDataFrame, used map data. stores location, shape attributes geographic features neighbourhoods.load first load INLA retrieve data fdmr example data store. ’ll use retrieve_tutorial_data . Next ’ll use load_tutorial_data function load spatial data want. Now make map study region map study region. COVID-19 data related covariate information included tutorial data package. ’ll load data using process used . first 6 rows data set can viewed using following code response variable study weekly reported number COVID-19 cases 6789 neighbourhoods main England period 2020-03-07 2022-03-26. week defined range Saturday Friday. Variable date indicates start date observation week variable week indicates week number data collected . Therefore, time frame study week beginning March 7, 2020 week beginning March 26, 2022 inclusive, spans 108 weeks. Variables LONG LAT indicate longitude latitude neighbourhood. plot weekly number reported COVID-19 cases spanning 108 weeks: weekly reported number COVID cases March 7, 2020 March 26, 2022. number studies linked different socioeconomic, demographic environmental factors explain variation COVID-19 infection rates across space (Sun, Hu, Xie (2021), Choi et al. (2021), Akinwumiju et al. (2022), Al Kindi et al. (2021), Kim et al. (2021), Wang et al. (2020), Berg, Present, Richardson (2021)). Based past studies data availability, selected set potential socioeconomic, demographic environmental variables model. covariate data collected MSOA England, can accessed https://www.nomisweb.co.uk/census/2021/bulk https://uk-air.defra.gov.uk/data/pcm-data. also considered two covariates related health care possible inclusion model, existing studies shown may affect infection rates COVID-19 (Harris Brunsdon (2021), Lee et al. (2022)). Table 1 provides full descriptions variables. Table1: Descriptions covariates study","code":"library(INLA) ## Loading required package: Matrix ## Loading required package: sp ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, ## which was just loaded, will retire in October 2023. ## Please refer to R-spatial evolution reports for details, especially ## https://r-spatial.org/r/2023/05/15/evolution4.html. ## It may be desirable to make the sf package available; ## package maintainers should consider adding sf to Suggests:. ## The sp package is now running under evolution status 2 ##      (status 2 uses the sf package in place of rgdal) ## This is INLA_23.09.09 built 2023-09-09 13:43:09 UTC. ##  - See www.r-inla.org/contact-us for how to get help. fdmr::retrieve_tutorial_data(dataset = \"covid\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/covid sp_data <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"spatial_data.rds\") sp_data@data$mapp <- 0 domain <- sp_data@data$mapp  fdmr::plot_map(polygon_data = sp_data, domain = domain, add_scale_bar = TRUE, polygon_fill_opacity = 0.5, palette = \"YlOrRd\") covid19_data <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"covid19_data.rds\") utils::head(covid19_data) ##       MSOA11CD       date week     LONG      LAT cases Population   IMD ## 6521 E02006663 2020-03-07    1 -1.77072 51.17063     3      12605 12.94 ## 2101 E02002160 2020-03-14    2 -2.07682 52.59541     4       7481 24.79 ## 3321 E02003411 2020-03-14    2 -0.57737 51.52327     8      11443 25.13 ## 4008 E02004108 2020-03-14    2 -1.43761 53.29906     4       7514 17.33 ## 3334 E02003424 2020-03-14    2 -0.71324 51.51317     4       8947  4.58 ## 2094 E02002153 2020-03-14    2 -2.05805 52.61565     3       7217 31.88 ##      carebeds.ratio AandETRUE perc.chinese perc.indian perc.bangladeshi ## 6521     0.01630534         0    0.2153846   0.5384615       0.02307692 ## 2101     0.01440074         0    0.4223307  18.2922001       0.11878052 ## 3321     0.01265956         1    0.2399232  16.6826615       0.67178503 ## 4008     0.02191863         0    0.1455411   0.2910823       0.10584811 ## 3334     0.02194874         0    1.3427866  10.4952197       0.21484585 ## 2094     0.00000000         0    0.2005884   2.6343942       0.05349024 ##      perc.pakistani   perc.ba    perc.bc  perc.wb      age1     age2     age3 ## 6521      0.0000000 1.2307692 0.35384615 89.54615 11.685839 21.01547 27.10829 ## 2101      0.5807048 1.7949056 1.82130131 63.15164 13.848416 19.51611 25.77196 ## 3321     30.8941139 4.2226488 1.44753679 17.99424 14.812549 23.80495 21.34056 ## 4008      0.2778513 0.1984652 0.07938608 94.98545 11.738089 16.34283 28.81288 ## 3334      4.0068751 1.0849715 0.40820711 61.38146  9.701576 20.73321 27.51760 ## 2094      0.1337256 1.2035304 1.39074619 87.79085 13.759180 16.95996 27.24124 ##          age4     pm25       no2 ## 6521 16.92979 6.608217  5.957610 ## 2101 17.99225 8.066084 14.479405 ## 3321 11.13344 8.308508 14.164620 ## 4008 24.12829 6.813326  8.356319 ## 3334 22.68917 7.822982 11.810846 ## 2094 21.53249 7.715645 12.522200 breaks_vec <- c(seq(as.Date(\"2020-03-07\"),   as.Date(\"2022-03-26\"),   by = \"3 week\" ), as.Date(\"2022-03-26\"))  cases_week <- dplyr::group_by(covid19_data, date) %>% dplyr::summarize(cases = sum(cases))  fdmr::plot_barchart(data = cases_week, x = cases_week$date, y = cases_week$cases, breaks = breaks_vec, x_label = \"Date\", y_label = \"Number of cases\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"model-specification","dir":"Articles","previous_headings":"","what":"Model specification","title":"COVID-19","text":"use Bayesian hierarchical model predict spatio-temporal COVID-19 infection rate neighbourhood level England. Let \\(Y_{}\\) denotes weekly number reported COVID cases neighbourhood \\(=1,\\ldots, n(=6789)\\) week \\(t=1,\\ldots, T(=108)\\) \\(N_{}\\) denotes (official) estimated population living neighbourhood \\(\\) week \\(t\\). Note data population size neighbourhood obtained 2021 census change time, .e., \\(N_{i1}=N_{i2}=\\ldots = N_{,108}\\) \\(\\). \\(Y_{}\\) assumed Poisson distribution parameters (\\(N_{}\\), \\(\\theta_{}\\)), \\(\\theta_{}\\) true unobserved COVID-19 infection rate / risk neighbourhood \\(\\) week \\(t\\). follow standard path modelling \\(\\theta_{}\\) log link Poisson start model linear predictor decomposes additively set covariates Gaussian latent process characterizing infection disease covariate effects accounted . proposed model given \\[\\begin{align} \\nonumber  Y_{}\\vert N_{}, \\theta_{} &\\sim \\text{Poisson}(N_{}\\theta_{}),\\ \\  =1,\\ldots,n;\\ \\  t=1,\\ldots,T,\\\\ log(\\theta_{} )&=\\boldsymbol{x_{}^{\\top}}\\boldsymbol{\\beta}+S(,t). \\end{align}\\] vector covariates (needed) given \\(\\boldsymbol{x_{}}\\) neighbourhood \\(\\) time period \\(t\\). \\(\\boldsymbol\\beta\\) vector regression parameters. \\(S(,t)\\) spatio-temporal random effect location \\(\\) time \\(t\\), modelled \\[S(,t)=\\alpha \\times S(,t-1)+\\omega(,t).\\] \\(S(,t)\\) follows stationary distribution first-order autoregressive process (AR(1)) \\(\\alpha\\) temporal dependence parameter takes value interval [-1,1], \\(\\alpha=1\\) indicating strong temporal dependence (first-order random walk), \\(\\alpha=0\\) corresponds independence across time. \\(\\omega(,t)\\) spatial random effect assumed arise multivariate normal distribution. \\(\\omega(,t)\\) follows zero-mean Gaussian field assumed temporally independent spatially dependent time period Matérn covariance function given \\[\\text{Cov}(\\omega(,t), \\omega(j,t))=\\frac{\\sigma^2}{2^{\\nu-1}\\Gamma(\\nu)}(\\kappa||-j||)^{\\nu}K_{\\nu}(\\kappa||-j||),\\] \\(K_{\\nu}(\\cdot)\\) modified Bessel function second kind, \\(\\Gamma(\\nu)\\) Gamma function. Matérn covariance function three hyperparameters: \\(\\sigma^2\\) controls marginal variance process S(,t). \\(\\kappa\\) controls spatial correlation range, can defined \\(\\rho=\\sqrt{8\\nu}/\\kappa\\). \\(\\nu\\) controls smoothness, higher values leads processes smoother. model implemented INLA-SPDE approach R programming. steps needed fitting model: Create triangulated mesh study region Build SPDE model based mesh set priors spatial parameters Define process evolves time set prior temporal parameter Define model formula","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"mesh-construction","dir":"Articles","previous_headings":"","what":"Mesh construction","title":"COVID-19","text":"implement SPDE approach, necessary discretize space creating triangulated mesh establishes set artificial neighbors across study region (.e., mainland England). allows calculation spatial autocorrelation observations. construction mesh impact model inferences predictions. Therefore, crucial develop good mesh ensure results overly sensitive mesh. Although construction mesh varies depending case study, guidelines available produce optimal mesh. vignette construct two-dimensional mesh using INLA::inla.mesh.2d() function. locations neighbourhoods passed function argument “loc” initial mesh nodes, arguments function tuned adjust shape resolution mesh necessary. Argument “max.edge” determines maximum permitted length triangle (lower values max.edge result higher mesh resolution). argument can take either scalar value, controls triangle edge lengths inner domain, length-two vector controls edge lengths inner domain outer extension avoid boundary effect. Although standard setting correct value max.edge, value max.edge close spatial range (.e., low resolution) complicate process fitting smooth SPDE. Specifically, Gaussian random field approximation might deviate strongly desired Matern structure, marginal variance vary domain rather constant, violates assumption stationary Gaussian process. Conversely, max.edge value small compared spatial range (.e., high resolution), mesh contain excessive number vertices, resulting computationally intensive fitting process may necessarily yield improved results. number research studies suggested max.edge value inner domain 1/3 1/10 times smaller spatial range (note spatial range parameter INLA GMRF distance correlation drops 0.13). Since spatial range known model fitted, initial guess needs made 1/5 spatial domain often used practice. , define argument “max.edge” outer extension triangle density two times lower inner domain (.e., twice triangle length outer extension edges), original spatial domain extended without increasing much computational burden. Lindgren Rue (2015) suggested extending domain interest distance least equal spatial range avoid boundary effect. function argument “offset” specifies size inner outer extensions around data locations. study, expand inner domain 1/4 spatial range initially assumed, outer domain amount spatial range. addition, also use parameter “cutoff” avoid building many small triangles close input locations. defines minimum allowed distance observation points. Points distance less cutoff value considered single mesh vertex. choose cutoff value equal 1/7 max.edge value inner domain. mesh study region displayed Figure @ref(fig:plotmesh), blue dots represent locations neighbourhoods. use INLA::inla.mesh.2d construct mesh. Triangulated mesh used build SPDE model.","code":"initial_range <- diff(range(sp_data@data[, \"LONG\"])) / 5  max_edge <- initial_range / 8  mesh <- INLA::inla.mesh.2d(   loc = sp_data@data[, c(\"LONG\", \"LAT\")],   max.edge = c(1, 2) * max_edge,   offset = c(initial_range / 4, initial_range),   cutoff = max_edge / 7 ) point_data <- sp_data@data[, c(\"LONG\", \"LAT\")]  fdmr::plot_mesh(mesh = mesh, point_data = point_data)"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"build-the-spde-model-on-the-mesh-and-set-priors-for-the-spatial-parameters","dir":"Articles","previous_headings":"","what":"Build the SPDE model on the mesh and set priors for the spatial parameters","title":"COVID-19","text":"use INLA::inla.spde2.pcmatern() function build SPDE model specify Penalised Complexity (PC) priors parameters Matérn field. PC priors parameters range marginal standard deviation Matérn field specified setting values \\(m_r\\), \\(p_r\\), \\(m_\\sigma\\) \\(p_\\sigma\\) relations P(spatial range<\\(m_r\\))= \\(p_r\\), P(\\(\\sigma>m_\\sigma\\))= \\(p_\\sigma\\). spatial range process distance correlation two values close 0.1. study use prior P(spatial range<1.480)= 0.5 spatial range parameter based exploratory variogram analysis. means probability spatial range smaller 1.480 degrees latitude (equivalent 164 kilometers) 0.5. \\(\\sigma\\) controls marginal standard deviation process, specified prior P(\\(\\sigma\\) >1)= 0.01.","code":"prior_range <- initial_range spde <- INLA::inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(prior_range, 0.5),   prior.sigma = c(1, 0.01) )"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"define-how-the-process-evolves-over-time-and-set-prior-for-the-temporal-parameter","dir":"Articles","previous_headings":"","what":"Define how the process evolves over time and set prior for the temporal parameter","title":"COVID-19","text":"previous step specified time periods spatial locations linked SPDE model. Now assume across time process evolves according first order autoregressive (AR(1)) process. specify PC prior temporal autocorrelation parameter \\(\\alpha \\[-1,1]\\). prior given rhoprior, PC prior P(\\(\\alpha>0\\))=0.9. order fit model, also need define temporal index (must integer starting 1) number discrete time points want model. use function bru() package inlabru fit model. bru expects coordinates data, thus transform covid19_data data set SpatialPointsDataFrame using function coordinates() sp package.","code":"rhoprior <- base::list(theta = list(prior = \"pccor1\", param = c(0, 0.9))) group_index <- covid19_data$week n_groups <- length(unique(covid19_data$week)) sp::coordinates(covid19_data) <- c(\"LONG\", \"LAT\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"define-the-model-formula","dir":"Articles","previous_headings":"","what":"Define the model formula","title":"COVID-19","text":"order fit spatio-temporal model, model formula needs defined, including response left-hand side fixed random effects right-hand side.","code":"formula <- cases ~ 0 + Intercept + IMD +   carebeds.ratio + AandETRUE +   perc.chinese + perc.indian + perc.bangladeshi + perc.pakistani + perc.ba + perc.bc + perc.wb +   age1 + age2 + age3 + age4 +   pm25 + no2 +   f(     main = coordinates,     model = spde,     group = group_index,     ngroup = n_groups,     control.group = list(       model = \"ar1\",       hyper = rhoprior     )   )"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"fit-the-model","dir":"Articles","previous_headings":"","what":"Fit the model","title":"COVID-19","text":"Finally, fit spatio-temporal model using spde approach AR(1) process calling function bru() package inlabru. NOTE: Since data size quite large memory requirements function call high. recommend running suitable high memory (MUCH ENOUGH?) system. case takes 13 hours complete.","code":"inlabru_model <- inlabru::bru(formula,   data = covid19_data,   family = \"poisson\",   E = covid19_data$Population,   control.family = list(link = \"log\"),   options = list(     control.inla = list(       reordering = \"metis\",       int.strategy = \"eb\"     ),     verbose = TRUE,     inla.mode = \"experimental\"   ) )"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"COVID-19","text":"can inspect results typing summary(inlabru_model),shows parameter estimates fixed random effects. marginal distributions hyperparameters can also obtained follows.","code":"model_summary <- summary(inlabru_model)  model_summary_fixed <- inlabru_model$summary.fixed model_hyperparams <- inlabru_model$marginals.hyperpar"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"summary-of-the-parameter-estimates-of-the-fixed-effects","dir":"Articles","previous_headings":"Results","what":"Summary of the parameter estimates of the fixed effects","title":"COVID-19","text":"model summary provided tutorial data package ’ll load now. NOTE: ’ve run full model don’t need load files . Table 2 reports regression coefficient values, estimated relative risks 95% credible intervals covariate COVID infection model. estimated relative risks 95% credible intervals computed exponentially transforming regression coefficients associated covariates described Table 1. relative risks relate realistic increases covariate, given brackets column 1 table. Table2: Estimated relative risks 95% credible intervals effects covariate COVID-19 infection. table shows clear evidence high level socio-economic deprivation associated increased COVID-19 incidence. increase 10 scores IMD significantly associated 0.5% decreased infection rate. number care home beds per adult also significantly associated COVID infection, neighbourhood increases care home beds ratio 0.01, estimated risk increases around 1.1%. addition, hospital emergency facilities neighbourhood diagnosed positively significantly associated higher infection risk (RR:1.0050, 95% CI: 1.0018-1.0081). Ethnicity appears overall strong association COVID-19 infection. Neighbourhoods greater percentage Chinese population lower risk infections. However, Indian Pakistani ethnic groups found small detrimental effect COVID infection, risk increasing 0.2% percentage Indian Pakistani ethnic groups neighbourhood increases 1%. African population associated decreased risk COVID-19 infection (RR:0.9961, 95% CI: 0.9955-0.9966), whereas Caribbean population statistically higher COVID-19 infections (RR: 1.0084, 95% CI: 1.0073-1.0095). Neighbourhoods greater percentage white British higher risk infections, 1% increase population associated statistically significant 0.4% increase COVID infection. addition, also found infection rate lower neighbourhoods greater population percentages adults age 65 years older (RR: 0.9937, 95% CI: 0.9932–0.9941) neighbourhoods greater percentages adults age 18–29 years (RR: 0.9962, 95% CI: 0.9958–0.9965). contrast, population 30 44 years old population 45 64 years old positively associated risk infections, although result former significant. Finally, elevated \\(\\text{PM}_{2.5}\\) concentrations statistically significantly associated COVID-19 incidence, \\(1 \\ \\mu g m^{-3}\\) increase concentrations associated 0.02% 0.80% increased risk. \\(10 \\ \\mu g m^{-3}\\) increase \\(\\text{}_2\\) concentrations associated positive, insignificant increase relative risk COVID infections (RR: 1.0015, 95% CI: 0.9915, 1.0116).","code":"model_summary <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"model_summary.rds\") model_summary_fixed <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"model_summary_fixed.rds\") model_hyperparams <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"model_hyperparams.rds\")  print(model_summary_fixed[2:nrow(model_summary_fixed), 1:5]) ##                           mean           sd    0.025quant      0.5quant ## IMD              -0.0005112128 6.255458e-05 -0.0006338175 -0.0005112128 ## carebeds.ratio    1.1166330921 4.605568e-02  1.0263656196  1.1166330921 ## AandETRUE         0.0049431635 1.615743e-03  0.0017763654  0.0049431635 ## perc.chinese     -0.0030466982 6.376484e-04 -0.0042964661 -0.0030466982 ## perc.indian       0.0024263610 2.034198e-04  0.0020276654  0.0024263610 ## perc.bangladeshi  0.0014271369 2.067729e-04  0.0010218694  0.0014271369 ## perc.pakistani    0.0023360953 1.877373e-04  0.0019681370  0.0023360953 ## perc.ba          -0.0039299175 2.873344e-04 -0.0044930825 -0.0039299175 ## perc.bc           0.0083423398 5.652759e-04  0.0072344193  0.0083423398 ## perc.wb           0.0044153274 1.466510e-04  0.0041278968  0.0044153274 ## age1             -0.0038339689 1.729288e-04 -0.0041729031 -0.0038339689 ## age2              0.0003332178 2.639185e-04 -0.0001840531  0.0003332178 ## age3              0.0024108905 3.152524e-04  0.0017930070  0.0024108905 ## age4             -0.0063447620 2.053866e-04 -0.0067473124 -0.0063447620 ## pm25              0.0041042717 1.973304e-03  0.0002366660  0.0041042717 ## no2               0.0001506359 5.135262e-04 -0.0008558570  0.0001506359 ##                     0.975quant ## IMD              -0.0003886081 ## carebeds.ratio    1.2069005647 ## AandETRUE         0.0081099616 ## perc.chinese     -0.0017969304 ## perc.indian       0.0028250566 ## perc.bangladeshi  0.0018324044 ## perc.pakistani    0.0027040536 ## perc.ba          -0.0033667525 ## perc.bc           0.0094502602 ## perc.wb           0.0047027580 ## age1             -0.0034950347 ## age2              0.0008504886 ## age3              0.0030287739 ## age4             -0.0059422116 ## pm25              0.0079718774 ## no2               0.0011571288"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"summary-of-the-hyperparameters","dir":"Articles","previous_headings":"Results","what":"Summary of the hyperparameters","title":"COVID-19","text":"parameter estimates spatial range parameter, marginal standard deviation latent Gaussian process AR(1) coefficient plot posterior distributions spatial range, standard deviation temporal dependence parameters spatio-temporal random effect, create list named list_marginals containing posterior distributions parameter. list, generate data frame margs, include additional column named ‘parameter’ specifies name corresponding distribution parameter. Spatial range estimated 0.297, AR(1) coefficient estimated 0.839, indicating high level temporal dependence. Posterior distributions spatial range, standard deviation temporal dependence parameters.","code":"model_summary$inla$hyperpar[, 1:5] ##                 mean    sd 0.025quant 0.5quant 0.975quant ## Range for f    0.297 0.003      0.291    0.298      0.301 ## Stdev for f    0.646 0.003      0.640    0.646      0.651 ## GroupRho for f 0.838 0.001      0.835    0.838      0.840 list_marginals <- list(   \"Spatial range\" = model_hyperparams$`Range for f`,   \"Stdev\" = model_hyperparams$`Stdev for f`,   \"AR(1)\" = model_hyperparams$`GroupRho for f` )  margs <- data.frame(do.call(rbind, list_marginals)) margs$parameter <- rep(names(list_marginals),   times = sapply(list_marginals, nrow) )  margs$parameter <-   factor(margs$parameter, levels = c(\"Spatial range\", \"Stdev\", \"AR(1)\"))  ggplot2::ggplot(margs, ggplot2::aes(x = x, y = y)) +   ggplot2::geom_line() +   ggplot2::facet_wrap(~parameter, scales = \"free\") +   ggplot2::labs(x = \"\", y = \"Density\") +   ggplot2::theme_bw()"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"temporal-evolution-of-infection-rate-predictions","dir":"Articles","previous_headings":"Results","what":"Temporal evolution of infection rate predictions","title":"COVID-19","text":"infection rate predictions model can computed using following codes, saved data frame called “predictions”. NOTE: cell run model run. Otherwise please run cell loads saved predictions file. date frame “predictions” provided tutorial data package, ’ll load now. figure displays boxplots predicted infection risk neighbourhoods time. can seen health inequalities COVID infection exist England, large differences estimated disease risks. Boxplots predicted infection rates across neighbourhoods time figure provides line plot average predicted risk 95% credible intervals week across England. COVID infection risk witnessed series fluctuations study period within range 0.0002 0.05, overall upward temporal trend can observed. initial peak mid-November 2020, infection levels declined rising mid-December 2020, driven emergence Alpha variant peaked early January 2021. week 5 June 2021, infection rate began rising mid-July estimated 0.5%, risk fell remained steady November. However, infection reached highest point week 8 January 2022 2.0%, decreased substantially early March 2022. average predicted infection risk weeks Finally, create map showing spatial pattern time averaged risks infection England. Map average predicted infection risks","code":"pred.mean <- inlabru_model$summary.fitted.values$mean[1:nrow(covid19_data)] pred.25 <- inlabru_model$summary.fitted.values$`0.025quant`[1:nrow(covid19_data)] pred.975 <- inlabru_model$summary.fitted.values$`0.975quant`[1:nrow(covid19_data)]  predictions <- cbind.data.frame(   \"date\" = covid19_data$date,   \"week\" = covid19_data$week,   \"MSOA11CD\" = covid19_data$MSOA11CD,   \"pred.mean\" = pred.mean,   \"pred.25\" = pred.25,   \"pred.975\" = pred.975 ) predictions <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"predictions.rds\") breaks_vec <- c(seq(as.Date(\"2020-03-07\"),   max(predictions$date),   by = \"3 week\" ), as.Date(\"2022-03-26\"))  fdmr::plot_boxplot(   data = predictions,   x = predictions$date,   y = predictions$pred.mean,   breaks = breaks_vec,   x_label = \"Week of date\",   y_label = \"Infection risk\" ) mean_week <- dplyr::group_by(predictions, date) %>% dplyr::summarize(   mean.prev = mean(pred.mean),   lc = mean(pred.25),   uC = mean(pred.975) )  fdmr::plot_line_average(   data = mean_week,   x = mean_week$date,   y1 = mean_week$mean.prev,   y2 = mean_week$lc,   y3 = mean_week$uC,   breaks = breaks_vec,   x_label = \"Week of date\",   y_label = \"Average risk\",   y_lim = c(0, 0.025) ) average_risk_by_nb <-   dplyr::group_by(predictions, MSOA11CD) %>% dplyr::summarize(ave.risk = mean(pred.mean))  sp_data@data$ave.risk <- average_risk_by_nb$ave.risk  domain <- sp_data@data$ave.risk  fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Risk\",   add_scale_bar = TRUE,   polygon_fill_opacity = 1,   polygon_line_colour = \"transparent\" )"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"evaluate-the-performance-of-prediction","dir":"Articles","previous_headings":"Results","what":"Evaluate the performance of prediction","title":"COVID-19","text":"Measuring prediction accuracy model critical aspect evaluating performance, especially context time-series data new information becomes available time. measure prediction accuracy model, moving time series window training validation data considered new data comes throughout pandemic. approach allows model continuously update parameters based latest available data, rather relying static dataset may reflect current situation. started initial training dataset 96 weeks 2020/03/07 2022/01/01, used predict infection risk \\(\\theta_{,t}\\) week \\(t = 97\\) neighbourhoods \\(\\). prediction compared actual observed values determine accuracy model. process repeated subsequent week new data becomes available. accuracy risk prediction measured root mean square error (RMSE), bias coverage probabilities 95% credible intervals corresponding risk estimates. RMSE quantifies average magnitude differences predicted observed values, lower value indicates better prediction performance. \\(\\text{RMSE}_t\\) risk estimates week \\(t\\) neighbourhoods calculated \\[\\text{RMSE}_t=\\sqrt{\\frac{1}{n_t}\\sum_{=1}^{n_t}(\\hat{\\theta}_{}-\\theta_{})^2},\\] \\(\\hat{\\theta}_{}\\) \\(\\theta_{}\\) predicted observed infection risk neighbourhood \\(\\) week \\(t\\) respectively. \\(n_t\\) total number neighbourhoods reported COVID infection data week \\(t\\). Bias measures average difference predicted observed values. bias risk predictions neighbourhoods week \\(t\\) calculated \\[\\text{Bias}_t=\\frac{1}{n_t}\\sum_{=1}^{n_t}(\\hat{\\theta}_{}-\\theta_{}).\\] uncertainty risk predictions can measured coverage probabilities 95% credible intervals. 95% coverage probability (denoted \\(\\text{CP}_t\\)) computed proportion 95% credible intervals \\(\\hat{\\theta}_{}\\) contain observed risk. addition, measure magnitude differences predicted observed values relation observed values, relative root mean square error (R-RMSE) relative bias (R-Bias) also computed. relative root mean square error (\\(\\text{R-RMSE}_t\\)) calculated \\[ \\text{R-RMSE}_t=\\sqrt{\\frac{1}{n_t}\\sum_{=1}^{n_t}\\left(\\frac{\\hat{\\theta}_{}-\\theta_{}}{\\theta_{}}\\right)^2}.\\] relative bias (\\(\\text{R-Bias}_t\\)) calculated \\[ \\text{R-Bias}_t=\\frac{1}{n_t}\\sum_{=1}^{n_t}\\left(\\frac{\\hat{\\theta}_{}-\\theta_{}}{\\theta_{}}\\right). \\] new data comes every week, previous data used training model, \\(\\text{RMSE}_t\\), \\(\\text{R-RMSE}_t\\), \\(\\text{Bias}_t\\), \\(\\text{R-Bias}_t\\) \\(\\text{CP}_t\\) updated using new validation data week \\(t\\). Finally, create time series \\(\\text{RMSE}_t\\), \\(\\text{Bias}_t\\) \\(\\text{CP}_t\\) week \\(t\\) \\((97,\\ldots, 108)\\), summarise progress predictive capabilities model time. values \\(\\text{RMSE}_t\\), \\(\\text{Bias}_t\\), \\(\\text{CP}_t\\), \\(\\text{R-RMSE}_t\\) \\(\\text{R-Bias}_t\\) week \\(t\\) \\((97,\\ldots, 108)\\) stored tutorial data package ’ll load data.frame containing data now. figure displays time series plots \\(\\text{RMSE}_t\\), \\(\\text{Bias}_t\\) \\(\\text{CP}_t\\). plots suggest model performs well predicting rate COVID-19 infection, RMSE bias values low (close 0) compared range observed risks, coverage probabilities close nominal 0.95 level. Table 3 provides median mean values \\(\\text{RMSE}_t\\), \\(\\text{Bias}_t\\), \\(\\text{CP}_t\\),\\(\\text{R-RMSE}_t\\) \\(\\text{R-Bias}_t\\) \\(t \\(97, . . . , 108)\\). RMSE, bias coverage probability model time. Table3: summary RMSE, bias coverage probabilities.","code":"predmetrics <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"predmetrics.rds\") breaks_vec <- c(seq(min(predmetrics$date),   max(predmetrics$date),   by = \"1 week\" ))  RMSEt <- predmetrics[, c(\"date\", \"RMSEt\")] Biast <- predmetrics[, c(\"date\", \"Biast\")] CPt <- predmetrics[, c(\"date\", \"CPt\")]  g1 <-   fdmr::plot_timeseries(     data = RMSEt,     # TODO - update these to just accept a string     x = \"date\",     y = \"RMSEt\",     breaks = breaks_vec,     x_label = \"Date\",     y_label = \"RMSE\",     y_lim = c(0, 0.05),     horizontal_y = 0   )  g2 <-   fdmr::plot_timeseries(     data = Biast,     x = \"date\",     y = \"Biast\",     breaks = breaks_vec,     x_label = \"Date\",     y_label = \"Bias\",     y_lim = c(-0.01, 0.01),     horizontal_y = 0   )  g3 <-   fdmr::plot_timeseries(     data = CPt,     x = \"date\",     y = \"CPt\",     breaks = breaks_vec,     x_label = \"Date\",     y_label = \"Coverage probability\",     y_lim = c(0, 1),     horizontal_y = 0.95   )  gridExtra::grid.arrange(g1, g2, g3, nrow = 1)"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"COVID-19","text":"study provides valuable insights spread evolution COVID-19 occurrences MSOA level mainland England March 7, 2020 March 26, 2022. found significant health inequalities COVID infection across England, magnitude inequalities appearing increased time, emphasizes need effective strategies address disparities COVID-19 risk different neighbourhoods. COVID infection risk England fluctuated time overall upward trend, people appear higher risk COVID infection June, July, December, January, likely due June July popular months travelling, outdoor activities social gatherings UK, December January associated holiday celebrations (Christmas New Year’s holiday), family gatherings, travel. events often involve close contact others, can increase risk COVID-19 transmission. Colder drier conditions winter months also make COVID-19 virus transmissible (Mecenas et al. (2020), Wang et al. (2021)). low estimated infection risks small variation first weeks study period probably due limited capacity COVID-19 testing first wave pandemic. Testing available priority groups comprehensive, meaning many infected people diagnosed virus. likely led -reporting confirmed COVID-19 cases, turn led low infection rates small variation. results model shown clear evidence socioeconomic deprivation positively associated increased COVID-19 incidence, aligns findings Oluyomi et al. (2021), Kulu Dorey (2021) virus hit harder areas higher deprivation. likely due individuals living deprived areas limited access healthcare facilities resources, exhibiting higher prevalence underlying health conditions, relying heavily public transportation, contribute higher infection rates. Ethnicity found strong association COVID-19 infection. Chinese African populations found associated lower risk infections, whereas Indian Pakistani ethnic groups, Caribbean population, white British population associated higher risk infections. lower infection rates Chinese might attributed greater emphasis collective responsibility community health, helped encourage adherence public health guidelines prevent spread virus, white British individuals appear less likely adhere recommended COVID-19 related health behaviours compared ethnic groups https://www.iser.essex.ac.uk/blog/2021/06/14/--ethnic-differences--adherence--recommended-health-behaviours-related--covid-19. Neighborhoods greater percentage adults aged 65 older, greater percentage adults aged 18-29, found lower risk infections, populations 30 44 years old, 45 64 years old, positively associated risk infections. findings may explained aspects vaccination rates, lifestyle health status. example, older people among first groups prioritized COVID-19 vaccination UK, leading lower COVID infection rates. Young adults (aged 18-29) may likely comply public health guidelines regulations, social distancing wearing masks, avoid exposure virus. Additionally, younger adults likely jobs allow work home, reducing exposure virus public spaces. Conversely, middle-aged adults (aged 45-64 years old) may likely work essential jobs require interact public, increasing exposure virus. Elevated \\(\\text{PM}_{2.5}\\) \\(\\text{}_2\\) levels also found positively associated COVID-19 infections. Exposure air pollution can cause inflammation damage respiratory system, may increase susceptibility respiratory infections COVID-19 (Fattorini Regoli (2020), Comunian et al. (2020)). Air pollution shown worsen underlying health conditions diabetes, cardiovascular, respiratory diseases, known risk factors severe illness COVID-19 (Semczuk-Kaczmarek et al. (2021)). important note relationship COVID-19 infection risk race, age, air pollution socioeconomic status complex multifactorial. results showed risk factors considered study well-established relationship COVID-19 infections, necessarily causal relationship. research needed understand mechanisms behind associations. Nonetheless, findings suggest targeted interventions specific age race groups may necessary control spread COVID-19 different neighborhoods, reducing air pollution levels important public health intervention mitigating spread COVID-19. analysis highlighted associations COVID-19 infection set socioeconomic, demographic environmental factors. several areas future work expand understanding spread evolution COVID-19. beneficial extend study period include recent data order examine potential changes associations COVID-19 risk various factors identified study. analysis can extended examine impacts potential factors, comorbidities COVID-19 vaccination rates, may contribute spread COVID-19. Including factors future studies provide comprehensive understanding determinants COVID-19 risk. information useful policy makers determining effective strategies controlling spread COVID-19 reducing health inequalities England. Finally, important extend study countries regions examine whether results study generalizable settings. provide valuable insights global spread COVID-19 inform development effective strategies targeted actions preventing spread virus.","code":""},{"path":[]},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"modelling-covid-19-infection-across-england","dir":"Articles","previous_headings":"","what":"Modelling COVID-19 infection across England","title":"COVID-19 MCMC (Space-time)","text":"tutorial ’ll cover work fitting spatio-temporal Bayesian hierarchical model (BHM) predict COVID-19 infection rate across England.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"study-aim-and-data-description","dir":"Articles","previous_headings":"","what":"Study aim and data description","title":"COVID-19 MCMC (Space-time)","text":"study describes fit spatio-temporal BHM areal data using Markov Chain Monte Carlo (MCMC) simulation method. first thing load packages used COVID-19 case study. study region mainland England, partitioned 6789 neighbourhoods Middle Layer Super Output Area (MSOA) scale. infections data total reported number COVID-19 cases MSOA Jan 8, 2022 March 26, 2022. shapefile study region SpatialPolygonsDataFrame, used map data. stores location, shape attributes geographic features neighbourhoods.","code":"library(INLA) library(inlabru) library(magrittr)"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"installing-carbayesst","dir":"Articles","previous_headings":"Study aim and data description","what":"Installing CARBayesST","title":"COVID-19 MCMC (Space-time)","text":"tutorial requires CARBayesST package may need install working tutorial.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"retrieving-and-loading-data","dir":"Articles","previous_headings":"Study aim and data description","what":"Retrieving and loading data","title":"COVID-19 MCMC (Space-time)","text":"first need retrieve infections data fdmr example data store unpack ’ll use retrieve_tutorial_data . COVID-19 data related covariate information included tutorial data package. ’ll load data using load_tutorial_data function. Next ’ll use load_tutorial_data function load spatial data want. study, use areal unit modelling approach fit BHM make model inference using MCMC method. , need construct non-negative symmetric \\(n \\times n\\) neighbourhood adjacency matrix \\(\\boldsymbol{W}\\) accounts spatio-temporal autocorrelation structure, \\(n=6789\\) number areal units. neighbourhood matrix specifies spatial closeness pairs areal units. elements \\(\\{w_{ij}\\}\\) \\(\\boldsymbol{W}\\) can either continuous binary, larger value \\(w_{ij}\\) represents MSOAs \\((,j)\\) spatially closer . use border sharing specification, \\(w_{ij}=1\\) MSOAs \\((,j)\\) share common geographical border, \\(w_{ij}=0\\) otherwise.","code":"fdmr::retrieve_tutorial_data(dataset = \"covidST_mcmc\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/covidst_mcmc st_covid <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"st_covid.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. sp_data <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"spatial_data.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. W_nb <- spdep::poly2nb(sp_data, row.names = rownames(sp_data@data)) ## Error in eval(expr, envir, enclos): object 'sp_data' not found w <- spdep::nb2mat(W_nb, style = \"B\") ## Error in eval(expr, envir, enclos): object 'W_nb' not found"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"model-specification","dir":"Articles","previous_headings":"","what":"Model specification","title":"COVID-19 MCMC (Space-time)","text":"use Bayesian hierarchical model predict spatio-temporal COVID-19 infection rate neighbourhood level England. Let \\(Y_{}\\) denotes weekly number reported COVID cases neighbourhood \\(=1,\\ldots, n(=6789)\\) week \\(t=1,\\ldots, T(=108)\\) \\(N_{}\\) denotes (official) estimated population living neighbourhood \\(\\) week \\(t\\). \\(Y_{}\\) assumed Poisson distribution parameters (\\(N_{}\\), \\(\\theta_{}\\)), \\(\\theta_{}\\) true unobserved COVID-19 infection rate MSOA \\(\\) week \\(t\\). follow standard path modelling \\(\\theta_{}\\) log link Poisson start model linear predictor decomposes additively set covariates Gaussian Markov Random Field process, characterises infection disease covariate effects accounted . general Bayesian hierarchical model commonly specified given \\[\\begin{align} \\nonumber  Y_{}\\vert N_{}, \\theta_{} &\\sim \\text{Poisson}(N_{}\\theta_{}),\\ \\  =1,\\ldots,n, t=1,\\ldots,T,\\\\ log(\\theta_{} )&=\\boldsymbol{x_{}^{\\top}}\\boldsymbol{\\beta}+\\phi_{}. \\end{align}\\] spatial random effects \\(\\{\\phi_{}\\}\\) included model account residual spatio-temporal autocorrelation adjusting covariates \\(\\boldsymbol{x_{}}\\). utilise spatio-temporal modelling structure proposed Rushworth, Lee, Mitchell (2014) model \\(\\{\\phi_{}\\}\\). given \\[\\begin{align} \\nonumber \\boldsymbol{\\phi_1}&\\sim \\text{N}\\left(\\boldsymbol{0}, \\tau^2\\boldsymbol{ Q}(\\boldsymbol{W})^{-1}\\right),\\\\ \\boldsymbol{\\phi_t}\\vert\\boldsymbol{\\phi_{t-1}}&\\sim \\text{N}\\left(\\alpha\\boldsymbol{\\phi_{t-1}},\\tau^2\\boldsymbol{Q}(\\boldsymbol{W},\\rho)^{-1}\\right), \\ \\ t=2,\\ldots, T,\\\\ \\end{align}\\] precision matrix \\(\\boldsymbol{Q}(\\boldsymbol{W},\\rho)\\) proposed Leroux et al.(2000). algebraic form matrix given \\[ \\boldsymbol{Q}(\\boldsymbol{W},\\rho)=\\rho[diag(\\boldsymbol{W1})-\\boldsymbol{W}]+(1-\\rho)\\boldsymbol{},\\] \\(\\boldsymbol{1}\\) \\(n\\times 1\\) vector ones, \\(n\\times n\\) identity matrix. \\(\\rho\\) \\(\\alpha\\) spatial temporal dependence parameters, respectively, \\(\\tau^2\\) variance parameter.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"define-the-model-formula","dir":"Articles","previous_headings":"","what":"Define the model formula","title":"COVID-19 MCMC (Space-time)","text":"order fit model, model formula needs defined, including response left-hand side fixed random effects right-hand side. select risk factors used COVID-19 tutorial.","code":"form <- cases ~ 1 + offset(log(Population)) + IMD + perc.wb + perc.ba + age1 + pm25"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"fit-the-model","dir":"Articles","previous_headings":"","what":"Fit the model","title":"COVID-19 MCMC (Space-time)","text":"Finally, fit spatio-temporal model using function ST.CARar() package CARBayesST developed Lee (2018) Lee, Rushworth, Napier (2018). first need organize COVID-19 infection covariate data specific format expected ST.CARar() function. details can found help file ‘ST.CARar()’. MSOAs without reported cases stored missing (NA) values data frame. :warning: Memory requirements: Running model requires large amount memory may fail run normal laptop / desktop. Now data frame ‘st_covid’ expected format. run model. Now summarise modelling results. “fitted_vals” stores predicted COVID-19 infection rate MSOA time point. “modfits” stores DIC WAIC values, measure goodness model fit. “mod_sum” provides values parameters \\(\\tau^2\\), \\(\\rho\\) \\(\\alpha\\). modelling results provided tutorial data package ’ll load now. NOTE: ’ve run full model don’t need load files . comparison purpose, also fit separate BHM dataset using INLA-SPDE approach. infection rates predicted INLA-SPDE approach saved date frame named “inla_preds” provided tutorial data package. ’ll load now. predictions two models merged one data frame named “mergedat”.","code":"time.points <- length(unique(st_covid$date)) n <- nrow(sp_data@data) dat <- data.frame(   MSOA11CD = rep(sp_data$MSOA11CD, time.points),   date = rep(sort(unique(st_covid$date)), each = n),   time = rep(1:time.points, each = n) )  dat$rowid <- 1:nrow(dat) out <- merge(dat, st_covid[, c(   \"MSOA11CD\",   \"date\",   \"MSOA11NM\",   \"cases\",   \"Population\" )], all.x = TRUE, by = c(\"MSOA11CD\", \"date\") )  dat <- out[order(out$rowid), ]  covars <- unique(st_covid[, c(   \"MSOA11CD\",   \"IMD\",   \"age1\",   \"perc.chinese\",   \"perc.indian\",   \"perc.wb\",   \"perc.bc\",   \"perc.ba\",   \"pm25\",   \"no2\" )])  out <- merge(dat, covars,   all.x = TRUE,   by = c(\"MSOA11CD\") ) dat <- out[order(out$rowid), ]  dat$pre <- dat$cases / dat$Population dat$logpre <- log(dat$pre) nbhoods <- unique(st_covid[, c(\"MSOA11CD\", \"Population\")])  for (i in 1:nrow(dat)) { #  this will take a few minutes   if (is.na(dat$Population[i])) {     dat$Population[i] <- nbhoods[       match(         dat[i, \"MSOA11CD\"],         nbhoods$MSOA11CD       ),       \"Population\"     ]   } }  st_covid <- dat rm(dat, nbhoods, out, covars) # remove non-necessary objects MCMC_model <- CARBayesST::ST.CARar(   formula = form,   data = st_covid,   family = \"poisson\",   W = w,   burnin = 10000,   n.sample = 30000,   thin = 10, AR = 1 ) fitted_vals <- exp(sum(apply(MCMC_model$samples$beta, 2, mean)) +   apply(MCMC_model$samples$phi, 2, mean)) fitted_vals <- cbind.data.frame(st_covid[, c(\"MSOA11CD\", \"date\")], fitted_vals) modfits <- MCMC_model$modelfit mod_sum <- MCMC_model$summary.results fitted_vals <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"fitted_vals.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. modfits <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"modfits.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. mod_sum <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"mod_sum.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. inla_preds <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"inla_preds.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. mergedat <- merge(inla_preds,   fitted_vals,   by = c(\"MSOA11CD\", \"date\") ) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'merge': object 'inla_preds' not found"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_ST_mcmc.html","id":"model-comparison","dir":"Articles","previous_headings":"","what":"Model comparison","title":"COVID-19 MCMC (Space-time)","text":"show DIC WAIC values model. model using MCMC approach performs better model using INLA-SPDE approach terms lower DIC WAIC values. Now compare posterior COVID-19 infection rate estimates two models. general, two models provide similar posterior COVID-19 infection rate estimates. regression coefficients estimates selected covariates models compared. Finally, spatial patterns average infection rate estimates time model displayed .","code":"inla_sum <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"INLAmodsum.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. modfit <- data.frame(   DIC = c(modfits[1], inla_sum[1]),   WAIC = c(modfits[2], inla_sum[2]) ) ## Error in eval(expr, envir, enclos): object 'modfits' not found rownames(modfit) <- c(\"MCMC\", \"INLA_SPDE\") ## Error: object 'modfit' not found modfit ## Error in eval(expr, envir, enclos): object 'modfit' not found plot(mergedat$mcmc.fitted.prev, mergedat$inla.fitted.prev, xlab = \"MCMC\", ylab = \"INLA_SPDE\", xlim = c(0, 0.06), ylim = c(0, 0.06), cex = 0.01) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'mergedat' not found boxplot(mergedat$mcmc.fitted.prev, mergedat$inla.fitted.prev,   names = c(\"MCMC\", \"INLA_SPDE\") ) ## Error in eval(expr, envir, enclos): object 'mergedat' not found summary_fixed <- fdmr::load_tutorial_data(dataset = \"covidST_mcmc\", filename = \"INLAfixed_sum.rds\") ## Error in get_tutorial_datapath(dataset = dataset, filename = filename): Invalid dataset, the folder /home/runner/fdmr/tutorial_data/covidST_mcmc does not exist. regr_est <- cbind.data.frame(   \"MCMC\" = mod_sum[1:6, 1],   \"INLA_SPDE\" = summary_fixed$mean ) ## Error in eval(expr, envir, enclos): object 'mod_sum' not found regr_est ## Error in eval(expr, envir, enclos): object 'regr_est' not found mcmc_mean_rate <- dplyr::group_by(mergedat, MSOA11CD) %>% dplyr::summarize(   mean.rate = mean(mcmc.fitted.prev) ) ## Error in eval(expr, envir, enclos): object 'mergedat' not found sp_data@data$mcmc_mean_rate <- mcmc_mean_rate$mean.rate ## Error in eval(expr, envir, enclos): object 'mcmc_mean_rate' not found domain <- sp_data@data$mcmc_mean_rate ## Error in eval(expr, envir, enclos): object 'sp_data' not found fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Rate\",   add_scale_bar = TRUE,   polygon_fill_opacity = 0.8,   polygon_line_colour = \"transparent\" ) ## Error in eval(expr, envir, enclos): object 'sp_data' not found INLA_mean_rate <- dplyr::group_by(mergedat, MSOA11CD) %>% dplyr::summarize(   mean.rate = mean(inla.fitted.prev) ) ## Error in eval(expr, envir, enclos): object 'mergedat' not found sp_data@data$INLA_mean_rate <- INLA_mean_rate$mean.rate ## Error in eval(expr, envir, enclos): object 'INLA_mean_rate' not found domain <- sp_data@data$INLA_mean_rate ## Error in eval(expr, envir, enclos): object 'sp_data' not found fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Rate\",   add_scale_bar = TRUE,   polygon_fill_opacity = 0.8,   polygon_line_colour = \"transparent\" ) ## Error in eval(expr, envir, enclos): object 'sp_data' not found"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"modelling-covid-19-infection-across-england","dir":"Articles","previous_headings":"","what":"Modelling COVID-19 infection across England","title":"COVID-19 MCMC","text":"tutorial ’ll cover work fitting purely spatial Bayesian model predict COVID-19 infection rate across England.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"study-aim-and-data-description","dir":"Articles","previous_headings":"","what":"Study aim and data description","title":"COVID-19 MCMC","text":"study describes fit purely spatial Bayesian hierarchical model (BHM) based Markov Chain Monte Carlo (MCMC) simulation method estimate spatial pattern COVID-19 infection rate England. first thing load packages used COVID-19 case study.","code":"library(INLA) library(inlabru)"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"install-carbayes","dir":"Articles","previous_headings":"Study aim and data description","what":"Install CARBayes","title":"COVID-19 MCMC","text":"tutorial requires CARBayes package, please install continuing tutorial.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"retrieving-data","dir":"Articles","previous_headings":"Study aim and data description > Install CARBayes","what":"Retrieving data","title":"COVID-19 MCMC","text":"study region mainland England, partitioned 6789 neighbourhoods Middle Layer Super Output Area (MSOA) scale. infections data total reported number COVID-19 cases MSOA Jan 8, 2022 March 26, 2022. shapefile study region SpatialPolygonsDataFrame, used map data. stores location, shape attributes geographic features neighbourhoods. first load INLA retrieve data fdmr example data store. ’ll use retrieve_tutorial_data . COVID-19 data related covariate information included tutorial data package. ’ll load data using load_tutorial_data function. Next ’ll use load_tutorial_data function load spatial data want. study, use areal unit modelling approach fit BHM make model inference using MCMC method. , need construct non-negative symmetric \\(n \\times n\\) neighbourhood adjacency matrix \\(\\boldsymbol{W}\\) accounts spatio-temporal autocorrelation structure, \\(n=6789\\) number areal units. neighbourhood matrix specifies spatial closeness pairs areal units. elements \\(\\{w_{ij}\\}\\) \\(\\boldsymbol{W}\\) can either continuous binary, larger value \\(w_{ij}\\) represents MSOAs \\((,j)\\) spatially closer . use border sharing specification, \\(w_{ij}=1\\) MSOAs \\((,j)\\) share common geographical border, \\(w_{ij}=0\\) otherwise.","code":"library(INLA) fdmr::retrieve_tutorial_data(dataset = \"covid_mcmc\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/covid_mcmc s_covid <- fdmr::load_tutorial_data(dataset = \"covid_mcmc\", filename = \"s_covid.rds\") sp_data <- fdmr::load_tutorial_data(dataset = \"covid_mcmc\", filename = \"spatial_data.rds\") W_nb <- spdep::poly2nb(sp_data, row.names = rownames(sp_data@data)) w <- spdep::nb2mat(W_nb, style = \"B\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"model-specification","dir":"Articles","previous_headings":"","what":"Model specification","title":"COVID-19 MCMC","text":"use Bayesian hierarchical model predict spatial COVID-19 infection rate MSOA level England. Let \\(Y_{}\\) denote total number reported COVID cases neighbourhood \\(=1,\\ldots, n(=6789)\\) study period, \\(N_{}\\) denote (official) estimated population living MSOA \\(\\). \\(Y_{}\\) assumed Poisson distribution parameters (\\(N_{}\\), \\(\\theta_{}\\)), \\(\\theta_{}\\) true unobserved COVID-19 infection rate MSAO \\(\\). follow standard path modelling \\(\\theta_{}\\) log link Poisson start model linear predictor decomposes additively set covariates Gaussian Markov Random Field process, characterises infection disease covariate effects accounted . general Bayesian hierarchical model commonly specified given \\[\\begin{align} \\nonumber  Y_{}\\vert N_{}, \\theta_{} &\\sim \\text{Poisson}(N_{}\\theta_{}),\\ \\  =1,\\ldots,n,\\\\ log(\\theta_{} )&=\\boldsymbol{x_{}^{\\top}}\\boldsymbol{\\beta}+\\phi_{}. \\end{align}\\] spatial random effects \\(\\{\\phi_i\\}\\) included model account residual spatio-temporal autocorrelation adjusting covariates \\(\\boldsymbol{x_{}}\\). utilise spatial modelling structure “BYM”, proposed Besag, York, Mollié (1991), model \\(\\{\\phi_i\\}\\). given \\[\\begin{align} \\nonumber \\phi_i &=\\phi_i^{(1)}+\\phi_i^{(2)}\\\\ \\phi_i^{(1)}\\vert\\boldsymbol\\phi_{-}^{(1)}&\\sim \\text{N}\\left( \\frac{\\sum_{j=1}^{n}w_{ij}\\phi_j^{(1)}}{\\sum_{j=1}^{n}w_{ij}}, \\frac{\\tau_1^2}{\\sum_{j=1}^{n}w_{ij}}\\right)\\\\ \\nonumber \\phi_i^{(2)}&\\sim \\text{N}(0, \\tau_2^2), \\end{align}\\] \\(\\phi_i\\) now consists two components. \\(\\phi_i^{(1)}\\) assigned intrinsic CAR prior (Besag et al., 1991), \\(\\phi_i^{(2)}\\) set independent identically normally distributed random effects, mean zero common variance \\(\\tau_2^2\\).","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"define-the-model-formula","dir":"Articles","previous_headings":"","what":"Define the model formula","title":"COVID-19 MCMC","text":"order fit spatial model, model formula needs defined, including response left-hand side fixed random effects right-hand side. First, consider scenario including covariates.","code":"form <- total.cases ~ 1 + stats::offset(log(population))"},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"fit-the-model","dir":"Articles","previous_headings":"","what":"Fit the model","title":"COVID-19 MCMC","text":"Finally, fit spatial model using function S.CARbym() package CARBayes developed Lee (2013). comparison purpose, fit separate BHM dataset using INLA approach. Likewise, uses BYM model spatial random effects. Finally, fit BHM dataset using INLA-SPDE approach.","code":"MCMC_model <- CARBayes::S.CARbym(   formula = form,   data = s_covid,   family = \"poisson\",   W = w,   burnin = 10000,   n.sample = 30000,   thin = 10,   verbose = F ) ## Error in loadNamespace(x): there is no package called 'CARBayes' s_covid$ID <- seq(1, nrow(s_covid)) formula <- total.cases ~ 1 + f(ID,   model = \"bym\",   graph = w )  INLA_model <- INLA::inla(formula,   data = s_covid,   family = \"poisson\",   E = s_covid$population,   control.compute = list(     dic = TRUE,     waic = TRUE,     cpo = TRUE   ),   verbose = FALSE ) initial_range <- diff(range(sp_data@data[, \"LONG\"])) / 5 max_edge <- initial_range / 8  mesh <- INLA::inla.mesh.2d(   loc = sp_data@data[, c(\"LONG\", \"LAT\")],   max.edge = c(1, 2) * max_edge,   offset = c(initial_range / 4, initial_range),   cutoff = max_edge / 7 )  prior_range <- initial_range spde <- inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(prior_range, 0.5),   prior.sigma = c(1, 0.01) )  s_covid_cp <- s_covid sp::coordinates(s_covid_cp) <- c(\"LONG\", \"LAT\") cmp <- total.cases ~ 0 + Intercept + f(main = coordinates, model = spde)  inlabru_model <- inlabru::bru(cmp,   data = s_covid_cp,   family = \"poisson\",   E = s_covid_cp$population,   control.family = list(link = \"log\"),   options = list(     verbose = FALSE   ) ) ## Warning in add_mapper(component$main, label = component$label, lhoods = lh, : All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. ##   Implicit latent intercept component specification is deprecated since version 2.1.14. ##   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). ## Warning in handle_problems(e_input): The input evaluation 'Intercept' for ## 'Intercept' failed. Perhaps the data object doesn't contain the needed ## variables? Falling back to '1'."},{"path":"https://4dmodeller.github.io/fdmr/articles/covid_mcmc.html","id":"model-comparison","dir":"Articles","previous_headings":"","what":"Model comparison","title":"COVID-19 MCMC","text":"terms model selection criteria, show different values model based DIC WAIC. model fitted using INLA-SPDE approach performs better two models terms lowest DIC WAIC values. compare posterior COVID-19 infection rate estimates models. general, models provide similar posterior COVID-19 infection rate estimates. spatial patterns infection rate estimates model displayed . Map predicted infection rates using MCMC. Map predicted infection rates using INLA-BYM. Map predicted infection rates using INLA-SPDE. Now consider scenario fitting models covariates interest. select several risk factors used COVID-19 tutorial. models described fitted compared incorporating covariate information. First fit BHM using MCMC method. Next fit BHM using INLA-BYM approach. Next fit BHM using INLA-SPDE approach. regression coefficients selected covariates models compared. general, models similar regression coefficients estimates. modelling performance results MCMC-BYM, INLA-BYM INLA-SPDE approaches can affected choice spatial model, inference method data characteristics. MCMC-BYM INLA-BYM use different inference methods, latter faster. MCMC-BYM approach, spatial correlation structure captured \\(n\\times n\\) adjacency matrix. Specifically, two locations adjacent geography, spatially correlated, leading data smoothing . However, INLA-SPDE approach uses Matern model, spatial correlation depends distance two locations, rather geographic adjacency. Thus, even two locations geographically adjacent, can still exhibit correlation.","code":"modfit <- data.frame(   DIC = c(MCMC_model$modelfit[1], INLA_model$dic$dic, inlabru_model$dic$dic),   WAIC = c(MCMC_model$modelfit[3], INLA_model$waic$waic, inlabru_model$waic$waic) ) ## Error in eval(expr, envir, enclos): object 'MCMC_model' not found rownames(modfit) <- c(\"MCMC\", \"INLA_BYM\", \"INLA_SPDE\") ## Error: object 'modfit' not found modfit ## Error in eval(expr, envir, enclos): object 'modfit' not found mcmc_fitted_prev <- exp(mean(MCMC_model$samples$beta) + apply(MCMC_model$samples$psi, 2, mean)) ## Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'mean': object 'MCMC_model' not found mcmc_lc <- exp(quantile(MCMC_model$samples$beta, 0.025) +   apply(MCMC_model$samples$psi, 2, quantile, 0.025)) ## Error in eval(expr, envir, enclos): object 'MCMC_model' not found mcmc_uc <- exp(quantile(MCMC_model$samples$beta, 0.975) +   apply(MCMC_model$samples$psi, 2, quantile, 0.975)) ## Error in eval(expr, envir, enclos): object 'MCMC_model' not found comb <- data.frame(   \"INLA_BYM\" = INLA_model$summary.fitted.values$mean,   \"INLA_lc\" = INLA_model$summary.fitted.values$`0.025quant`,   \"INLA_uc\" = INLA_model$summary.fitted.values$`0.975quant`,   \"INLA_SPDE\" = inlabru_model$summary.fitted.values$mean[1:nrow(s_covid)],   \"INLA_SPDE_lc\" = inlabru_model$summary.fitted.values$`0.025quant`[1:nrow(s_covid)],   \"INLA_SPDE_uc\" = inlabru_model$summary.fitted.values$`0.975quant`[1:nrow(s_covid)],   \"MCMC\" = mcmc_fitted_prev,   \"MCMC_lc\" = mcmc_lc,   \"MCMC_uc\" = mcmc_uc ) ## Error in eval(expr, envir, enclos): object 'mcmc_fitted_prev' not found pairs(comb[, c(\"MCMC\", \"INLA_SPDE\", \"INLA_BYM\")],   pch = 19, cex = 0.3, col = \"orange\", lower.panel = panel.smooth ) ## Error in eval(expr, envir, enclos): object 'comb' not found boxplot(comb[, c(\"MCMC\", \"INLA_SPDE\", \"INLA_BYM\")]) ## Error in eval(expr, envir, enclos): object 'comb' not found sp_data@data$est.rate.mcmc <- mcmc_fitted_prev ## Error in eval(expr, envir, enclos): object 'mcmc_fitted_prev' not found domain <- sp_data@data$est.rate.mcmc legend_values <- sp_data@data$est.rate.mcmc  fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Rate\",   add_scale_bar = TRUE,   polygon_fill_opacity = 0.8, ) sp_data@data$est.rate.inlabym <- INLA_model$summary.fitted.values$mean  domain <- sp_data@data$est.rate.inlabym legend_values <- sp_data@data$est.rate.inlabym  fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Rate\",   add_scale_bar = TRUE,   polygon_fill_opacity = 0.8, ) sp_data@data$est.rate.inlaspde <- inlabru_model$summary.fitted.values$mean[1:nrow(s_covid)]  domain <- sp_data@data$est.rate.inlaspde legend_values <- sp_data@data$est.rate.inlaspde  fdmr::plot_map(   polygon_data = sp_data,   domain = domain,   palette = \"Reds\",   legend_title = \"Rate\",   add_scale_bar = TRUE,   polygon_fill_opacity = 0.8, ) form <- total.cases ~ 1 + offset(log(population)) +   IMD + perc.wb + perc.ba + age1 + pm25  MCMC_model2 <- CARBayes::S.CARbym(   formula = form,   data = s_covid,   family = \"poisson\",   W = w,   burnin = 10000,   n.sample = 30000,   thin = 10,   verbose = F ) ## Error in loadNamespace(x): there is no package called 'CARBayes' formula <- total.cases ~ 1 + f(ID,   model = \"bym\",   graph = w ) + IMD + perc.wb + perc.ba + age1 + pm25  INLA_model2 <- INLA::inla(formula,   data = s_covid,   family = \"poisson\",   E = s_covid$population,   control.compute = list(     dic = TRUE,     waic = TRUE,     cpo = TRUE   ),   verbose = FALSE ) cmp <- total.cases ~ 0 + Intercept + f(main = coordinates, model = spde) +   IMD + perc.wb + perc.ba + age1 + pm25  inlabru_model2 <- inlabru::bru(cmp,   data = s_covid_cp,   family = \"poisson\",   E = s_covid_cp$population,   control.family = list(link = \"log\"),   options = list(     verbose = FALSE   ) ) ## Warning in add_mapper(component$main, label = component$label, lhoods = lh, : All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. ##   Implicit latent intercept component specification is deprecated since version 2.1.14. ##   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). ## Warning in handle_problems(e_input): The input evaluation 'Intercept' for ## 'Intercept' failed. Perhaps the data object doesn't contain the needed ## variables? Falling back to '1'. regr_est <- cbind.data.frame(   \"MCMC\" = MCMC_model2$summary.results[1:(nrow(MCMC_model2$summary.results) - 2), 1],   \"INLA_BYM\" = INLA_model2$summary.fixed[, 1],   \"INLA_SPDE\" = inlabru_model2$summary.fixed[, 1] ) ## Error in eval(expr, envir, enclos): object 'MCMC_model2' not found regr_est ## Error in eval(expr, envir, enclos): object 'regr_est' not found"},{"path":"https://4dmodeller.github.io/fdmr/articles/data_preprocessing.html","id":"aim-and-data-description","dir":"Articles","previous_headings":"","what":"Aim and data description","title":"Data pre-processing","text":"tutorial, provide short tutorial data pre-processing, involves transforming raw data desired format object running Bayesian Hierarchical Model (BHM) fdmr package. illustrate process, use COVID-19 infection data practical example. COVID-19 tutorial, aim fit Bayesian spatio-temporal model predict COVID-19 infection rates across mainland England space time, investigate impacts socioeconomic, demographic environmental factors COVID-19 infection. study region mainland England, partitioned 6789 Middle Layer Super Output Areas (MSOAs). raw shapefile study region obtained ONS Open Geography Portal, stores location, shape attributes geographic features MSOAs. First ’ll retrieve tutorial dataset preprocessing. load shapefile R, store object named sp_data. type object sp_data SpatialPolygonsDataFrame. retrieve projection attributes shapefile, .e., sp_data, transform original coordinate reference system (CRS) new CRS, World Geodetic System 1984 (WGS84). COVID-19 tutorial, raw COVID-19 infections data related covariate data obtained official UK Government COVID-19 dashboard Office National Statistics (ONS). data initially downloaded, organised saved CSV file format. CSV file can imported R using utils::read.csv() function. type object covid19_data data.frame. first 6 rows data set can viewed using following code data frame contains 23 columns. MSOA11CD represents spatial identifier data observation. Variable cases response variable, weekly reported number COVID-19 cases 6789 MSOAs main England period 2022-01-01 2022-03-26. Variable date indicates start date observation week COVID-19 infections data MSOA reported. Variable week indicates week index number data observation collected . Columns LONG LAT indicate longitude latitude MSOA. Variable Population indicates population size MSOA. remaining columns store data covariate MSOA week. Therefore, expected observation measurement data format spatio-temporal Bayesian hierarchical model COVID-19 tutorial data frame includes one column response variable (e.g., cases), two columns spatial location observation (e.g., LONG LAT), one column containing time point indices indicating observation collected (e.g., week = 1, 2, …). model incorporates covariates, covariate data also included data frame, covariate stored one column. Users can use variable names columns, long ensure consistency used defining model formula fitting model. following table provides summary expected data format running BHM fdmr package: sp_data covid19_data expected data object format, now possess essential information required fitting BHM visualising results. details regarding model fitting process can found COVID-19 tutorial.","code":"fdmr::retrieve_tutorial_data(dataset = \"preprocessing\") ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, ## which was just loaded, will retire in October 2023. ## Please refer to R-spatial evolution reports for details, especially ## https://r-spatial.org/r/2023/05/15/evolution4.html. ## It may be desirable to make the sf package available; ## package maintainers should consider adding sf to Suggests:. ## The sp package is now running under evolution status 2 ##      (status 2 uses the sf package in place of rgdal) ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/preprocessing shapefilepath <- fdmr::get_tutorial_datapath(dataset = \"preprocessing\", filename = \"MSOA_(Dec_2011)_Boundaries_Super_Generalised_Clipped_(BSC)_EW_V3.shp\") sp_data <- rgdal::readOGR(dsn = shapefilepath) ## Please note that rgdal will be retired during October 2023, ## plan transition to sf/stars/terra functions using GDAL and PROJ ## at your earliest convenience. ## See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution ## rgdal: version: 1.6-7, (SVN revision 1203) ## Geospatial Data Abstraction Library extensions to R successfully loaded ## Loaded GDAL runtime: GDAL 3.4.1, released 2021/12/27 ## Path to GDAL shared files: /usr/share/gdal ## GDAL binary built with GEOS: TRUE  ## Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821] ## Path to PROJ shared files: /home/runner/.local/share/proj:/usr/share/proj ## PROJ CDN enabled: FALSE ## Linking to sp version:2.0-0 ## To mute warnings of possible GDAL/OSR exportToProj4() degradation, ## use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal. ## OGR data source with driver: ESRI Shapefile  ## Source: \"/home/runner/fdmr/tutorial_data/preprocessing/MSOA_(Dec_2011)_Boundaries_Super_Generalised_Clipped_(BSC)_EW_V3.shp\", layer: \"MSOA_(Dec_2011)_Boundaries_Super_Generalised_Clipped_(BSC)_EW_V3\" ## with 7201 features ## It has 11 fields class(sp_data) ## [1] \"SpatialPolygonsDataFrame\" ## attr(,\"package\") ## [1] \"sp\" sp::proj4string(sp_data) ## [1] \"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs\" sp_data <- sp::spTransform(sp_data, sp::CRS(\"+proj=longlat +datum=WGS84 +no_defs\")) ## Warning: PROJ support is provided by the sf and terra packages among others covid19_data_filepath <- fdmr::get_tutorial_datapath(dataset = \"preprocessing\", filename = \"covid19_data.csv\") covid19_data <- utils::read.csv(file = covid19_data_filepath) class(covid19_data) ## [1] \"data.frame\" utils::head(covid19_data) ##    MSOA11CD     date week     LONG      LAT cases Population   IMD ## 1 E02002415 1/1/2022    1 -1.54813 53.77558    57       7698 68.39 ## 2 E02002391 1/1/2022    1 -1.66579 53.80466   203       7380 20.85 ## 3 E02002377 1/1/2022    1 -1.51938 53.81505    78       7955 52.34 ## 4 E02002431 1/1/2022    1 -1.58525 53.74190   204       8366 27.40 ## 5 E02002998 1/1/2022    1 -2.37911 51.37245    77       6023 12.12 ## 6 E02002999 1/1/2022    1 -2.39800 51.37034    83       5597 19.13 ##   carebeds.ratio AandETRUE perc.chinese perc.indian perc.bangladeshi ## 1    0.000000000         0    0.7112918    1.041534      12.66353360 ## 2    0.014004309         0    0.4419192    1.022727       0.01262626 ## 3    0.001402525         0    0.6257489    3.608042      20.48994808 ## 4    0.003969340         0    1.0094136    2.302370       0.01134173 ## 5    0.013117143         0    1.3052209    1.857430       0.31793842 ## 6    0.000000000         0    1.1537096    1.100461       0.65672701 ##   perc.pakistani    perc.ba   perc.bc   perc.wb     age1     age2     age3 ## 1     22.8883526 18.4554808 1.4098819 20.157500 21.17433 23.13588 19.32970 ## 2      0.5808081  1.1237374 0.1262626 91.136364 15.01355 21.31436 26.76152 ## 3     27.7592864  9.8655306 4.2604181  9.253095 21.87304 22.95412 16.07794 ## 4      0.7258705  1.4630827 0.3515935 85.210389 17.77432 21.92207 24.98207 ## 5      0.1171352  0.6860776 0.4685408 80.722892 38.53561 14.36161 18.61199 ## 6      0.1597444  0.3727370 0.3727370 84.700035 18.31338 18.59925 23.36966 ##        age4     pm25       no2 ## 1  5.520915 8.909063 18.108010 ## 2 16.463415 7.430964 15.525150 ## 3  6.712759 7.913701 18.095600 ## 4 13.387521 7.540963 16.344490 ## 5 13.132990 7.082593  7.628312 ## 6 19.403252 6.926548  7.073514"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"setting-up-the-r-environment","dir":"Articles","previous_headings":"","what":"Setting up the R environment","title":"Hydrology","text":"INLA inlabru installed please check installation instructions continuing. First load INLA download data tutorial data repository using retrieve_tutorial_data.","code":"library(INLA) ## Loading required package: Matrix ## Loading required package: sp ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, ## which was just loaded, will retire in October 2023. ## Please refer to R-spatial evolution reports for details, especially ## https://r-spatial.org/r/2023/05/15/evolution4.html. ## It may be desirable to make the sf package available; ## package maintainers should consider adding sf to Suggests:. ## The sp package is now running under evolution status 2 ##      (status 2 uses the sf package in place of rgdal) ## This is INLA_23.09.09 built 2023-09-09 13:43:09 UTC. ##  - See www.r-inla.org/contact-us for how to get help. fdmr::retrieve_tutorial_data(dataset = \"hydro\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/hydro"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"kvilldal-dam-area","dir":"Articles","previous_headings":"","what":"Kvilldal dam area","title":"Hydrology","text":"First look location dam making map plotting stream gauges . want mark position dam stream gauges map ’ll create data.frame pass plot_map function names positions. ’ll create list points use (dplyr::bind_rows)[https://dplyr.tidyverse.org/reference/bind.html] function create data.frame . ’re now ready plot map, passing polygon data, markers optionally fill opacity. map can see dam, resevoir, catchment area, two stream gauges. area inside shape water accumulates, area outside boundary water goes elsewhere. important later including ERA5-land precipitation data.","code":"# TODO : here is a good example for the map function norway_polygon_path <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"Kvilldal_Catch_Boundary.geojson\") norway_polygon <- rgdal::readOGR(norway_polygon_path) ## Please note that rgdal will be retired during October 2023, ## plan transition to sf/stars/terra functions using GDAL and PROJ ## at your earliest convenience. ## See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution ## rgdal: version: 1.6-7, (SVN revision 1203) ## Geospatial Data Abstraction Library extensions to R successfully loaded ## Loaded GDAL runtime: GDAL 3.4.1, released 2021/12/27 ## Path to GDAL shared files: /usr/share/gdal ## GDAL binary built with GEOS: TRUE  ## Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821] ## Path to PROJ shared files: /home/runner/.local/share/proj:/usr/share/proj ## PROJ CDN enabled: FALSE ## Linking to sp version:2.0-0 ## To mute warnings of possible GDAL/OSR exportToProj4() degradation, ## use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal. ## OGR data source with driver: GeoJSON  ## Source: \"/home/runner/fdmr/tutorial_data/hydro/Kvilldal_Catch_Boundary.geojson\", layer: \"Kvilldal_Catch_Boundary\" ## with 1 features ## It has 5 fields norway_polygon <- sf::st_as_sf(norway_polygon,   coords = c(\"longitude\", \"latitude\"),   crs = \"+proj=utm +zone=32\" )   sfc <- sf::st_transform(norway_polygon, crs = \"+proj=longlat +datum=WGS84\") suldalsvatnet_dam <- list(longitude = 6.517174, latitude = 59.490720, label = \"Suldalsvatnet Dam\") stream_gauge_13 <- list(longitude = 6.5395789, latitude = 59.5815849, label = \"Stream Gauge 13\") stream_gauge_14 <- list(longitude = 6.7897968, latitude = 59.7531662, label = \"Stream Gauge 14\")  points <- list(suldalsvatnet_dam, stream_gauge_13, stream_gauge_14) markers <- dplyr::bind_rows(points) fdmr::plot_map(polygon_data = sfc, markers = markers, polygon_fill_opacity = 0.5)"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"stream-gauge-data","dir":"Articles","previous_headings":"","what":"Stream gauge data","title":"Hydrology","text":"stream gauge data measured average daily liters/second pass area. data goes back many years, sometimes decades, ’ll take subset data October 2021. can now plot average stream flow using plot_timeseries   rescale data Z-score since values different two stream gauges can see, two different stream gauges record different amount stream flow. Therefore likely normalize data using zscore. response variable study stream flow measurement. amount water passes stream gauge representative amount water accumulate resevoir. Thus, order understand changes time, important understand physical processes drive water streams feed resevoir.","code":"streamdata_13 <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"NVEobservations_s36_13.csv\") streamdata_14 <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"NVEobservations_s36_14.csv\")  data_13 <- read.csv(streamdata_13) data_13$date <- as.Date(data_13$time) data_13 <-   subset(data_13, date >= \"2021-10-01\" & date <= \"2021-10-31\") row.names(data_13) <- NULL data_13$time_index <- seq(1, 31, 1)  data_14 <- read.csv(streamdata_14) data_14$date <- as.Date(data_14$time) data_14 <-   subset(data_14, date >= \"2021-10-01\" & date <= \"2021-10-31\") row.names(data_14) <- NULL data_14$time_index <- seq(1, 31, 1) fdmr::plot_timeseries(data = data_13, x = \"time\", y = \"value\", x_label = \"Time\", y_label = \"Stream Flow: Daily Average (Liter/s)\", line_colour = \"violet\") fdmr::plot_timeseries(data = data_14, x = \"time\", y = \"value\", x_label = \"Time\", y_label = \"Stream Flow: Daily Average (Liter/s)\", line_colour = \"limegreen\") data_13$value <- scale(data_13$value) data_14$value <- scale(data_14$value)"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"era5-land-data","dir":"Articles","previous_headings":"","what":"ERA5-land data","title":"Hydrology","text":"ERA5-land data includes many variables. use daily precipitation data. ERA5-land precipitation comes reanalysis climate model. ERA5-land data gridded however need data assigned catchment shapes. ’ll first load data, ensure projected using correct coordinate reference system (CRS) plot map.  Now ’ve ensured everything projected correctly can use plot_interactive_map plot RasterBrick catchment area polygon. loads Shiny app allows selection layers RasterBrick using date slider. also allows update properties objects plotted map map tiles. NOTE: interactive map won’t render web version notebook Shiny app. try get fixed soon possible. Next create data.frame raster_df containing precipitation data. convert RasterBrick precipitation data just plotted data.frame. want get day component date date. look names layer RasterBrick can see prepended X, due raster allowing layer names start numbers. First need remove X, numbers_only. convert strings Date objects using to_dates finally using lubridate::day get just day component date. Finally, set names columns data.frame. need figure ERA5 precipitation pixels closest stream gauge can match data regression. First need calculate distance pixel stream gauge, use minimum distance choose stream gauge. first convert lat/long coordinates UTM match pixel precipation data nearest stream gauge. data.frame pixel_dist_gauge needs replicated number time points, case, layers RasterBrick. Now create new SpatialPointDataFrame called inla_data model fitting. data frame contains response predictor data spatial location time point.","code":"era5_location <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"era5_land_daily.nc\") era5_precip <- raster::stack(era5_location) ## Loading required namespace: ncdf4 era5_precip %>%   raster::values() %>%   raster::hist(main = \"Total Precipitation\", col = \"violet\") sr <- \"+proj=utm +zone=32\" projected_raster <- raster::projectRaster(era5_precip, crs = sr)  era5_precip_cropped <- raster::mask(projected_raster, norway_polygon) era5_precip_cropped <- terra::crop(era5_precip_cropped, raster::extent(norway_polygon), snap = \"near\") fdmr::plot_interactive_map(raster_data = era5_precip_cropped, polygon_data = sfc) raster_df <- data.frame(raster::rasterToPoints(era5_precip_cropped)) raster_df <- data.table::melt(data.table::setDT(raster_df), id.vars = c(\"x\", \"y\"), variable.name = \"time\")  raster_df$time <- lubridate::day(fdmr::to_dates(fdmr::numbers_only(raster_df$time)))  raster_df <- setNames(raster_df, c(\"x\", \"y\", \"time\", \"precip\")) pixel_coords <- unique(sp::coordinates(era5_precip_cropped)) s13_utm <- fdmr::latlong_to_utm(   lat = stream_gauge_13$latitude,   lon = stream_gauge_13$longitude ) s14_utm <- fdmr::latlong_to_utm(   lat = stream_gauge_14$latitude,   lon = stream_gauge_14$longitude )  s13 <- data.frame(x = s13_utm[[1]], y = s13_utm[[2]]) s14 <- data.frame(x = s14_utm[[1]], y = s14_utm[[2]])  pixel_dist_gauge <- data.frame(   x = pixel_coords[, 1],   y = pixel_coords[, 2],   dist_s1 = rep(NA, nrow(pixel_coords)),   dist_s2 = rep(NA, nrow(pixel_coords)),   min_s = rep(NA, nrow(pixel_coords)),   streamflow = rep(NA, nrow(pixel_coords)) ) for (i in seq_len(nrow(pixel_coords))) {   pixel_dist_gauge$dist_s1[i] <- sqrt((pixel_dist_gauge$x[i] - s13$x)^2 + (pixel_dist_gauge$y[i] - s13$y)^2)    pixel_dist_gauge$dist_s2[i] <- sqrt((pixel_dist_gauge$x[i] - s14$x)^2 + (pixel_dist_gauge$y[i] - s14$y)^2)    pixel_dist_gauge$min_s[i] <- which.min(c(pixel_dist_gauge$dist_s1[i], pixel_dist_gauge$dist_s2[i])) } n_time <- raster::nlayers(era5_precip)  pixel_dist_gauge <- do.call(rbind, replicate(n_time, pixel_dist_gauge, simplify = FALSE)) pixel_dist_gauge$time <- rep(1:n_time, each = nrow(pixel_coords))  streamdata <- list(data_13, data_14)  get_stream_data <- function(row) {   which_stream_data <- streamdata[[row[\"min_s\"]]]   data_at_row_time_index <- which_stream_data[which_stream_data[, c(\"time_index\")] == row[\"time\"], ]   return(data_at_row_time_index$value) }  pixel_dist_gauge$streamflow <- apply(pixel_dist_gauge, 1, get_stream_data) inla_data <- merge(pixel_dist_gauge, raster_df, by = c(\"time\", \"x\", \"y\")) inla_data <- subset(inla_data, select = c(\"x\", \"y\", \"streamflow\", \"precip\", \"time\"))  sp::coordinates(inla_data) <- c(\"x\", \"y\")  head(inla_data@data) ##   streamflow      precip time ## 1 -0.7379358 0.007305657    1 ## 2 -0.7379358 0.006965242    1 ## 3 -0.7379358 0.006590370    1 ## 4 -0.7379358 0.006557765    1 ## 5 -0.7379358 0.007222239    1 ## 6 -0.7379358 0.006858168    1 head(inla_data@coords) ##          x       y ## 1 331417.8 6583370 ## 2 342677.8 6594470 ## 3 348307.8 6594470 ## 4 353937.8 6594470 ## 5 353937.8 6605570 ## 6 359567.8 6594470"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"creating-the-bhm-using-4d-modeller","dir":"Articles","previous_headings":"","what":"Creating the BHM using 4D-Modeller","title":"Hydrology","text":"order model 4D-Modeller need : Create spacial mesh SPDE model can evaluated Build SPDE model Define process evolves time","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"mesh-resolution","dir":"Articles","previous_headings":"Creating the BHM using 4D-Modeller","what":"Mesh resolution","title":"Hydrology","text":"Create triangulated mesh study region quick look .","code":"# TODO: it would be nice to map the mesh onto the dataset using the mapmaker function i am suggesting e <- era5_precip_cropped@extent resolution <- raster::res(era5_precip_cropped) sr <- \"+proj=utm +zone=32\"  xres <- resolution[1] * 2 yres <- resolution[2] * 2  xy <- sp::coordinates(era5_precip_cropped)  # Maybe this makes the mesh smaller xy <- xy[seq(1, nrow(xy), by = 2), ] colnames(xy) <- c(\"LONG\", \"LAT\") # mesh <- INLA::inla.mesh.2d(loc=xy, max.edge=c(xres*1000, xres*10000), cutoff=2000, crs=sr) # mesh <- INLA::inla.mesh.2d(loc=xy, max.edge=c(xres*1, xres*100), cutoff=2000, crs=sr)  mesh <- INLA::inla.mesh.2d(loc = xy, max.edge = c(xres * 1, xres * 100), cutoff = 75, crs = sr)  plot(mesh)"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"priors","dir":"Articles","previous_headings":"Creating the BHM using 4D-Modeller","what":"Priors","title":"Hydrology","text":"priors describing unobserved variannce distributed region. , far away center process cease spatially correlate surrounding environment. put different way, raining hill top, far hill must notice ’s raining . case, set prior range 20km. model time dependency. order fit model, also need define temporal index number discrete time points want model. INLA model requires time indicies must integer starting 1.","code":"# prior.range<-0.296 # the prior range is the distance that the process should stop effecting, so in this case it is currently 20km away from the node center prior_range <- 20.0 spde <- INLA::inla.spde2.pcmatern(   mesh = mesh,   prior.range = c(prior_range, 0.5),   prior.sigma = c(1, 0.01) ) rhoprior <- base::list(theta = list(prior = \"pccor1\", param = c(0, 0.9))) group_index <- inla_data@data$time n_groups <- length(unique(group_index))"},{"path":"https://4dmodeller.github.io/fdmr/articles/hydro.html","id":"model-inference","dir":"Articles","previous_headings":"Creating the BHM using 4D-Modeller","what":"Model Inference","title":"Hydrology","text":"model predicts streamflow given precipitation fixed effect SPDE model assumes correlation structure streamflow data due unobserved variables. Likely unobserved co-variates local elevation, temperature, soil permeability, presence vegetation. Now ’s time see output","code":"formula1 <- streamflow ~ 0 + Intercept + precip  formula2 <- streamflow ~ 0 + Intercept + precip +   f(     main = coordinates,     model = spde,     group = group.index,     ngroup = n_groups,     control.group = list(       model = \"ar1\",       hyper = rhoprior     )   ) inlabru_model1 <- inlabru::bru(formula1,   data = inla_data,   family = \"gaussian\",   options = list(     verbose = TRUE   ) ) ## Warning in add_mapper(component$main, label = component$label, lhoods = lh, : All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. ##   Implicit latent intercept component specification is deprecated since version 2.1.14. ##   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)'). ## Warning in handle_problems(e_input): The input evaluation 'Intercept' for ## 'Intercept' failed. Perhaps the data object doesn't contain the needed ## variables? Falling back to '1'. inlabru_model2 <- inlabru::bru(formula2,   data = inla_data,   family = \"gaussian\",   options = list(     verbose = TRUE   ) ) ## Warning in add_mapper(component$main, label = component$label, lhoods = lh, : All covariate evaluations for 'Intercept' are NULL; an intercept component was likely intended. ##   Implicit latent intercept component specification is deprecated since version 2.1.14. ##   Use explicit notation '+ Intercept(1)' instead (or '+1' for '+ Intercept(1)').  ## Warning in add_mapper(component$main, label = component$label, lhoods = lh, : The input evaluation 'Intercept' for 'Intercept' failed. Perhaps the data object doesn't contain the needed variables? Falling back to '1'. ## Warning in handle_problems(e_input): The input evaluation 'group.index' for ## 'f.group' failed. Perhaps the data object doesn't contain the needed variables? ## Falling back to '1'. # TODO : this could be where the model_eval function I recommend could be used summary(inlabru_model1) ## inlabru version: 2.9.0 ## INLA version: 23.09.09 ## Components: ## Intercept: main = linear(Intercept), group = exchangeable(1L), replicate = iid(1L) ## precip: main = linear(precip), group = exchangeable(1L), replicate = iid(1L) ## Likelihoods: ##   Family: 'gaussian' ##     Data class: 'SpatialPointsDataFrame' ##     Predictor: streamflow ~ . ## Time used: ##     Pre = 0.528, Running = 0.267, Post = 0.0449, Total = 0.839  ## Fixed effects: ##             mean    sd 0.025quant 0.5quant 0.975quant   mode kld ## Intercept -0.248 0.049     -0.343   -0.248     -0.152 -0.248   0 ## precip    23.923 3.503     17.052   23.923     30.792 23.923   0 ##  ## Model hyperparameters: ##                                         mean    sd 0.025quant 0.5quant ## Precision for the Gaussian observations 1.09 0.052       0.99     1.09 ##                                         0.975quant mode ## Precision for the Gaussian observations       1.20 1.09 ##  ## Deviance Information Criterion (DIC) ...............: 2394.72 ## Deviance Information Criterion (DIC, saturated) ....: 873.36 ## Effective number of parameters .....................: 2.98 ##  ## Watanabe-Akaike information criterion (WAIC) ...: 2394.28 ## Effective number of parameters .................: 2.53 ##  ## Marginal log-Likelihood:  -1215.68  ##  is computed  ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)') summary(inlabru_model2) ## inlabru version: 2.9.0 ## INLA version: 23.09.09 ## Components: ## Intercept: main = linear(Intercept), group = exchangeable(1L), replicate = iid(1L) ## precip: main = linear(precip), group = exchangeable(1L), replicate = iid(1L) ## f: main = spde(coordinates), group = ar1(group.index), replicate = iid(1L) ## Likelihoods: ##   Family: 'gaussian' ##     Data class: 'SpatialPointsDataFrame' ##     Predictor: streamflow ~ . ## Time used: ##     Pre = 0.645, Running = 82.3, Post = 2.5, Total = 85.4  ## Fixed effects: ##             mean    sd 0.025quant 0.5quant 0.975quant   mode kld ## Intercept -0.248 0.049     -0.343   -0.248     -0.152 -0.248   0 ## precip    23.923 3.502     17.053   23.923     30.791 23.923   0 ##  ## Random effects: ##   Name     Model ##     f SPDE2 model ##  ## Model hyperparameters: ##                                           mean     sd 0.025quant 0.5quant ## Precision for the Gaussian observations  1.090  0.052      0.990    1.089 ## Range for f                             33.084 53.410      3.052   17.912 ## Stdev for f                              0.248  0.271      0.017    0.163 ## GroupRho for f                           0.681  0.398     -0.477    0.855 ##                                         0.975quant  mode ## Precision for the Gaussian observations      1.196 1.087 ## Range for f                                159.986 7.200 ## Stdev for f                                  0.967 0.048 ## GroupRho for f                               0.998 0.999 ##  ## Deviance Information Criterion (DIC) ...............: 2394.62 ## Deviance Information Criterion (DIC, saturated) ....: 873.53 ## Effective number of parameters .....................: 2.94 ##  ## Watanabe-Akaike information criterion (WAIC) ...: 2394.20 ## Effective number of parameters .................: 2.50 ##  ## Marginal log-Likelihood:  -1216.00  ##  is computed  ## Posterior summaries for the linear predictor and the fitted values are computed ## (Posterior marginals needs also 'control.compute=list(return.marginals.predictor=TRUE)')"},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"has-the-model-actually-crashed","dir":"Articles","previous_headings":"","what":"Has the model actually crashed?","title":"INLA FAQ","text":"model stop running give error like inla.inlaprogram..crash(): inla-program exited error. …..? give messages actually crashed? INLA models can take time produce solutions often times give messages like “failed factorize Q”. However mean model completely failed, iteration complete ’s task. Allow model run long needs returns crash message.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"are-you-running-the-model-in-verbose-mode","dir":"Articles","previous_headings":"","what":"Are you running the model in verbose mode?","title":"INLA FAQ","text":"model can run verbose mode outputs feedback. feedback can useful diagnosing issues. Running verbose mode done like :","code":"fit.mod<-bru(formula, data =XX,                    family = XX,                    options = list(                      inla.mode=\"classic\", # or “inla.mode=\"experimental\"                      verbose = TRUE) )"},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"memory-issues","dir":"Articles","previous_headings":"","what":"Memory issues","title":"INLA FAQ","text":"large data set? many mesh nodes? mesh well designed (e.g., isolated triangles)? tried reducing number mesh nodes testing mesh size avoids errors?","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"inla-modeclassic-or-inla-modeexperimental","dir":"Articles","previous_headings":"","what":"inla.mode=\"classic\" or inla.mode=\"experimental\"","title":"INLA FAQ","text":"inlabru two modes “classic” “experimental”. often case switch mode model crash get result. , add parameter either inla.mode=\"classic\" inla.mode=\"experimental\" INLAbru call function. , ’s something like:","code":"fit.mod<-bru(formula, data =XX,                    family = XX,                    options = list(                      inla.mode=\"classic\", # or “inla.mode=\"experimental\"                      verbose = TRUE) )"},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"how-many-threads-are-you-using","dir":"Articles","previous_headings":"","what":"How many threads are you using?","title":"INLA FAQ","text":"default, inlabru use however many threads available. However can cause issues. can limit number threads num.threads, setting num.threads=\"1:1\":","code":"fit.mod<-bru(formula, data =XX,                    family = XX,                    options = list(                      num.threads=\"1:1\",                       verbose = TRUE)               )"},{"path":"https://4dmodeller.github.io/fdmr/articles/inlaFAQ.html","id":"have-you-selected-reasonable-control-parameters","dir":"Articles","previous_headings":"","what":"Have you selected reasonable control parameters?","title":"INLA FAQ","text":"INLA number options can accessed fitting formula using options parameter. list options rather large encourage explore experiment . Typically looks something like:","code":"fit.mod<-bru(formula, data =XX, family = XX,             options = list(                      control.inla = list(                        reordering = \"metis\",                        int.strategy = \"eb\"),                      verbose = TRUE ) )"},{"path":"https://4dmodeller.github.io/fdmr/articles/mapping.html","id":"polygons","dir":"Articles","previous_headings":"","what":"Polygons","title":"Map Plotting","text":"’ll first start plotting polygon data map. ’ll use data use Hydrology tutorial, display catchment area map. First need retrieve example data, load raster data file. Next need manipulate data ensure plot area correctly, Now can plot polygon leaflet map using plot_map.","code":"fdmr::retrieve_tutorial_data(dataset = \"hydro\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/hydro norway_polygon_location <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"Kvilldal_Catch_Boundary.geojson\") norway_polygon <- rgdal::readOGR(norway_polygon_location) ## Please note that rgdal will be retired during October 2023, ## plan transition to sf/stars/terra functions using GDAL and PROJ ## at your earliest convenience. ## See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution ## rgdal: version: 1.6-7, (SVN revision 1203) ## Geospatial Data Abstraction Library extensions to R successfully loaded ## Loaded GDAL runtime: GDAL 3.4.1, released 2021/12/27 ## Path to GDAL shared files: /usr/share/gdal ## GDAL binary built with GEOS: TRUE  ## Loaded PROJ runtime: Rel. 8.2.1, January 1st, 2022, [PJ_VERSION: 821] ## Path to PROJ shared files: /home/runner/.local/share/proj:/usr/share/proj ## PROJ CDN enabled: FALSE ## Linking to sp version:2.0-0 ## To mute warnings of possible GDAL/OSR exportToProj4() degradation, ## use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal. ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## OGR data source with driver: GeoJSON  ## Source: \"/home/runner/fdmr/tutorial_data/hydro/Kvilldal_Catch_Boundary.geojson\", layer: \"Kvilldal_Catch_Boundary\" ## with 1 features ## It has 5 fields ## Warning in rgdal::readOGR(norway_polygon_location): Z-dimension discarded norway_polygon <- sf::st_as_sf(norway_polygon,   coords = c(\"longitude\", \"latitude\"),   crs = \"+proj=utm +zone=32\" )  sfc <- sf::st_transform(norway_polygon, crs = \"+proj=longlat +datum=WGS84\") fdmr::plot_map(polygon_data = sfc)"},{"path":"https://4dmodeller.github.io/fdmr/articles/mapping.html","id":"rasters","dir":"Articles","previous_headings":"","what":"Rasters","title":"Map Plotting","text":"can also plot raster data onto map. ’ll now read raster data NetCDF file. using raster::stack function creates RasterStack object contains number RasterLayer objects. hold ERA5 precipitation data day month October 2021. can see ’ve got stack 31 layers, one day October. list dates stack can want plot Leaflet map need ensure coordinate reference system (CRS) correct. want plot data overlaps rain catchment area polygon plotted earlier, mask data using raster::mask crop using terra::crop. ’re now read plot raster data. Let’s select single layer stack, first day October, plot precipitation measurements day polygon previously plotted. Now ’re ready plot polygon raster data.","code":"era5_data_filepath <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"era5_land_daily.nc\") era5_precip <- raster::stack(era5_data_filepath) ## Loading required namespace: ncdf4 era5_precip ## class      : RasterStack  ## dimensions : 10, 14, 140, 31  (nrow, ncol, ncell, nlayers) ## resolution : 0.1, 0.1000002  (x, y) ## extent     : 5.9, 7.3, 59.2, 60.2  (xmin, xmax, ymin, ymax) ## crs        : +proj=longlat +datum=WGS84 +no_defs  ## names      : X2021.10.01, X2021.10.02, X2021.10.03, X2021.10.04, X2021.10.05, X2021.10.06, X2021.10.07, X2021.10.08, X2021.10.09, X2021.10.10, X2021.10.11, X2021.10.12, X2021.10.13, X2021.10.14, X2021.10.15, ... names(era5_precip) ##  [1] \"X2021.10.01\" \"X2021.10.02\" \"X2021.10.03\" \"X2021.10.04\" \"X2021.10.05\" ##  [6] \"X2021.10.06\" \"X2021.10.07\" \"X2021.10.08\" \"X2021.10.09\" \"X2021.10.10\" ## [11] \"X2021.10.11\" \"X2021.10.12\" \"X2021.10.13\" \"X2021.10.14\" \"X2021.10.15\" ## [16] \"X2021.10.16\" \"X2021.10.17\" \"X2021.10.18\" \"X2021.10.19\" \"X2021.10.20\" ## [21] \"X2021.10.21\" \"X2021.10.22\" \"X2021.10.23\" \"X2021.10.24\" \"X2021.10.25\" ## [26] \"X2021.10.26\" \"X2021.10.27\" \"X2021.10.28\" \"X2021.10.29\" \"X2021.10.30\" ## [31] \"X2021.10.31\" projected_raster <- raster::projectRaster(era5_precip, crs = \"+proj=utm +zone=32\") crop_era5 <- raster::mask(projected_raster, norway_polygon) crop_era5 <- terra::crop(crop_era5, raster::extent(norway_polygon), snap = \"near\") raster_image <- crop_era5$X2021.10.01 fdmr::plot_map(raster_data = raster_image, polygon_data = sfc, palette = \"viridis\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/mapping.html","id":"interactive-mapping","dir":"Articles","previous_headings":"","what":"Interactive mapping","title":"Map Plotting","text":"can plot data interactive leaflet map using plot_interactive_map function. launches Shiny app allowing customise plot better investigate data. couple examples showing use interactive plotting tool.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/mapping.html","id":"hydroelectric-power","dir":"Articles","previous_headings":"Interactive mapping","what":"Hydroelectric Power","title":"Map Plotting","text":"want create plot map covering rain catchment area around power plant. read GeoJSON file containing coordinates catchment area make sure ’s correct coordinate reference system plot map. Next read ECMWF Reanalysis v5 (ERA5) precipitation data NetCDF file. data now ready pass interactive plotting function.","code":"norway_polygon_location <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"Kvilldal_Catch_Boundary.geojson\") norway_polygon <- rgdal::readOGR(norway_polygon_location) ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## Warning: OGR support is provided by the sf and terra packages among others ## OGR data source with driver: GeoJSON  ## Source: \"/home/runner/fdmr/tutorial_data/hydro/Kvilldal_Catch_Boundary.geojson\", layer: \"Kvilldal_Catch_Boundary\" ## with 1 features ## It has 5 fields ## Warning in rgdal::readOGR(norway_polygon_location): Z-dimension discarded norway_polygon <- sf::st_as_sf(norway_polygon,   coords = c(\"longitude\", \"latitude\"),   crs = \"+proj=utm +zone=32\" )  norway_polygon <- sf::st_transform(norway_polygon, crs = \"+proj=longlat +datum=WGS84\") era5_data_filepath <- fdmr::get_tutorial_datapath(dataset = \"hydro\", filename = \"era5_land_daily.nc\") era5_precip <- raster::stack(era5_data_filepath) era5_precip <- raster::projectRaster(era5_precip, crs = \"+proj=utm +zone=32\") fdmr::plot_interactive_map(raster_data = era5_precip, polygon_data = norway_polygon)"},{"path":"https://4dmodeller.github.io/fdmr/articles/meshbuilder.html","id":"customise-initial-parameters","dir":"Articles","previous_headings":"","what":"Customise initial parameters","title":"Mesh building","text":"want customise initial parameters used build mesh can pass Now spatial data loaded can think initial parameters mesh ’re going create. ’ll calculate initial range max edge values data pass mesh_builder function. values used values initial mesh ’s created can changed within app. Now ’re ready start app.","code":"args(fdmr::mesh_builder) initial_range <- diff(range(sp_data@data[, \"LONG\"])) / 5 max_edge <- initial_range / 8  max_edge_fin <- c(1, 2) * max_edge offset <- c(initial_range / 4, initial_range) cutoff <- max_edge / 7 fdmr::mesh_builder(spatial_data = sp_data, max_edge = max_edge_fin, offset = offset, cutoff = cutoff)"},{"path":"https://4dmodeller.github.io/fdmr/articles/meshbuilder.html","id":"run-checks-on-mesh","dir":"Articles","previous_headings":"","what":"Run checks on mesh","title":"Mesh building","text":"provide simple function check meshes created using mesh builder tool. user interface click “Check mesh” run number tests mesh. Currently : Check number mesh nodes isn’t greater number measurments Check number triangles isn’t greater number measurements Check isolated triangles use mesh checking functionality must pass measuremnet data fdmr::mesh_builder function. use COVID-19 data. Create mesh design ’re finished click “Check mesh” button. passes created mesh fdmr::mesh_checker function returns list containing errors found mesh.","code":"covid19_data <- fdmr::load_tutorial_data(dataset = \"covid\", filename = \"covid19_data.rds\") fdmr::mesh_builder(spatial_data = sp_data, obs_data = covid19_data)"},{"path":"https://4dmodeller.github.io/fdmr/articles/meshbuilder.html","id":"exporting-your-mesh","dir":"Articles","previous_headings":"","what":"Exporting your mesh","title":"Mesh building","text":"export mesh click Code tab copy paste code used created mesh.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"aim-and-data-description","dir":"Articles","previous_headings":"","what":"Aim and data description","title":"Priors exploration","text":"tutorial ’ll show example exploring impact different priors spatial temporal autocorrelation parameters model inference results obtained INLA-SPDE approach. Bayesian spatio-temporal model different priors fitted COVID-19 infections data Bristol predict COVID-19 infection rate across Bristol. study region Bristol city, partitioned 55 neighbourhoods Middle Layer Super Output Area (MSOA) scale. shapefile study region shape SpatialPolygonsDataFrame, used map data. stores location, shape attributes geographic features neighbourhoods. first load INLA retrieve data fdmr example data store. ’ll use retrieve_tutorial_data . Next ’ll use load_tutorial_data function load spatial data want. Now make map study region. map study region. COVID-19 data Bristol included tutorial data package. ’ll load data using process used first 6 rows data set can viewed using following code response variable “cases” study weekly reported number COVID-19 cases MSOA Bristol period 2021-12-25 2022-03-26. “prevalence” observed COVID-19 infection rate, computed ratio “cases” “Population” MSOA. use Bayesian hierarchical model predict spatio-temporal COVID-19 infection rate MSOA level Bristol. response variable count data likelihood model commonly used Poisson model.","code":"library(INLA) ## Loading required package: Matrix ## Loading required package: sp ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, ## which was just loaded, will retire in October 2023. ## Please refer to R-spatial evolution reports for details, especially ## https://r-spatial.org/r/2023/05/15/evolution4.html. ## It may be desirable to make the sf package available; ## package maintainers should consider adding sf to Suggests:. ## The sp package is now running under evolution status 2 ##      (status 2 uses the sf package in place of rgdal) ## This is INLA_23.09.09 built 2023-09-09 13:43:09 UTC. ##  - See www.r-inla.org/contact-us for how to get help. fdmr::retrieve_tutorial_data(dataset = \"priors\") ##  ## Tutorial data extracted to  /home/runner/fdmr/tutorial_data/priors sp_data <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"spatial_dataBris.rds\") sp_data@data$mapp <- 0 domain <- sp_data@data$mapp fdmr::plot_map(polygon_data = sp_data, domain = domain, add_scale_bar = TRUE, polygon_fill_opacity = 0.5, palette = \"YlOrRd\") covid19_data <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"covid19_dataBris.rds\") utils::head(covid19_data) ##           UtlaName       date week  MSOA11CD cases Population  prevalence ## 3 Bristol, City of 2021-12-25    1 E02003014    89       8292 0.010733237 ## 4 Bristol, City of 2021-12-25    1 E02003015    99       6692 0.014793784 ## 5 Bristol, City of 2021-12-25    1 E02003016    99       8169 0.012118986 ## 6 Bristol, City of 2021-12-25    1 E02003017    74       6118 0.012095456 ## 7 Bristol, City of 2021-12-25    1 E02003018    69       5870 0.011754685 ## 9 Bristol, City of 2021-12-25    1 E02003020    55       6416 0.008572319 ##       LONG      LAT ## 3 -2.66729 51.51507 ## 4 -2.59093 51.49491 ## 5 -2.57357 51.49471 ## 6 -2.61209 51.48767 ## 7 -2.65070 51.48954 ## 9 -2.62725 51.49219"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"model-specification","dir":"Articles","previous_headings":"","what":"Model specification","title":"Priors exploration","text":"Let \\(Y_{}\\) denotes weekly number reported COVID cases neighbourhood \\(=1,\\ldots, n(=55)\\) week \\(t=1,\\ldots, T(=14)\\) \\(N_{}\\) denotes (official) estimated population living neighbourhood \\(\\) week \\(t\\). \\(Y_{}\\) assumed Poisson distribution parameters (\\(N_{}\\), \\(\\theta_{}\\)), \\(\\theta_{}\\) true unobserved COVID-19 infection rate / risk neighbourhood \\(\\) week \\(t\\). follow standard path modelling \\(\\theta_{}\\) log link Poisson start model linear predictor decomposes additively set covariates Gaussian latent process characterizing infection disease covariate effects accounted . proposed model given \\[\\begin{align} \\nonumber  Y_{}\\vert N_{}, \\theta_{} &\\sim \\text{Poisson}(N_{}\\theta_{}),\\ \\  =1,\\ldots,n;\\ \\  t=1,\\ldots,T,\\\\ log(\\theta_{} )&=\\boldsymbol{x_{}^{\\top}}\\boldsymbol{\\beta}+S(,t). \\end{align}\\] vector covariates (needed) given \\(\\boldsymbol{x_{}}\\) neighbourhood \\(\\) time period \\(t\\). \\(\\boldsymbol\\beta\\) vector regression parameters. \\(S(,t)\\) spatio-temporal random effect location \\(\\) time \\(t\\), modelled \\[S(,t)=\\alpha \\times S(,t-1)+\\omega(,t).\\] \\(S(,t)\\) follows stationary distribution first-order autoregressive process (AR(1)) \\(\\alpha\\) temporal dependence parameter takes value interval [-1,1], \\(\\alpha=1\\) indicating strong temporal dependence (first-order random walk), \\(\\alpha=0\\) corresponds independence across time. \\(\\omega(,t)\\) spatial random effect assumed arise multivariate normal distribution. \\(\\omega(,t)\\) follows zero-mean Gaussian field assumed temporally independent spatially dependent time period Matérn covariance function given \\[\\text{Cov}(\\omega(,t), \\omega(j,t))=\\frac{\\sigma^2}{2^{\\nu-1}\\Gamma(\\nu)}(\\kappa||-j||)^{\\nu}K_{\\nu}(\\kappa||-j||),\\] \\(K_{\\nu}(\\cdot)\\) modified Bessel function second kind, \\(\\Gamma(\\nu)\\) Gamma function. Matérn covariance function three hyperparameters: \\(\\sigma^2\\) controls marginal variance process S(,t). \\(\\kappa\\) controls spatial correlation range, can defined \\(\\rho=\\sqrt{8\\nu}/\\kappa\\). \\(\\nu\\) controls smoothness, higher values leads processes smoother. model implemented INLA-SPDE approach R programming. steps needed fitting model: Create triangulated mesh study region Build SPDE model based mesh set priors spatial parameters Define process evolves time set prior temporal parameter Define model formula","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"mesh-construction","dir":"Articles","previous_headings":"","what":"Mesh construction","title":"Priors exploration","text":"implement INLA-SPDE approach, necessary discretize space creating triangulated mesh establishes set artificial neighbors across study region. use INLA::inla.mesh.2d construct mesh.","code":"initial_range <- diff(base::range(sp_data@data[, \"LONG\"])) / 3 max_edge <- initial_range / 2 mesh <- INLA::inla.mesh.2d(   loc = sp_data@data[, c(\"LONG\", \"LAT\")],   max.edge = c(1, 2) * max_edge,   offset = c(initial_range, initial_range),   cutoff = max_edge / 7 )"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"build-the-spde-model-on-the-mesh-and-set-priors-for-the-spatial-parameters","dir":"Articles","previous_headings":"","what":"Build the SPDE model on the mesh and set priors for the spatial parameters","title":"Priors exploration","text":"fit spatio-temporal BHM, essential define prior distributions model parameters associated spatio-temporal autocorrelation. choice priors depends specific research questions, relies prior research findings expert knowledge. carefully selecting specifying priors, can capture uncertainty prior beliefs spatial temporal patterns data. priors play crucial role Bayesian inference, inform estimation model parameters subsequent predictions. Exploring different priors allows us assess sensitivity model results choice prior distributions. sensitivity analysis helps us understand robustness conclusions drawn BHM provides insights impact prior assumptions final inference. Therefore, context COVID-19 study, investigate influence varying priors spatial temporal autocorrelation parameters model inference. use INLA::inla.spde2.pcmatern() function build SPDE model specify Penalised Complexity (PC) priors parameters Matérn field. PC priors parameters range (\\(\\rho\\)) marginal standard deviation (\\(\\sigma\\)) Matérn field specified setting values “prior_range”, “ps_range”, “prior_sigma”, “pg_sigma” relations P(\\(\\rho\\) < prior_range) = ps_range, P(\\(\\sigma\\) > prior_sigma) = pg_sigma. spatial range \\(\\rho\\) process distance correlation two values close 0.1. P(\\(\\rho\\) < prior_range) = ps_range indicates probability \\(\\rho\\) smaller prior_range ps_range, P(\\(\\sigma\\) > prior_sigma) = pg_sigma indicates probability \\(\\sigma\\) larger prior_sigma pg_sigma.","code":""},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"define-how-the-process-evolves-over-time-and-set-prior-for-the-temporal-parameter","dir":"Articles","previous_headings":"","what":"Define how the process evolves over time and set prior for the temporal parameter","title":"Priors exploration","text":"previous step specified time periods spatial locations linked SPDE model. Now assume across time process evolves according first order autoregressive (AR(1)) process. specify PC prior temporal autocorrelation parameter \\(\\alpha\\). PC prior \\(\\alpha\\) specified setting values “prior_alpha” “pg_alpha” relations P(\\(\\alpha\\) > prior_alpha) = pg_alpha, indicating probability \\(\\alpha\\) greater prior_alpha pg_alpha. Now create dataframe “priors_dat” contains four different sets values “prior_range”, “ps_range”, “prior_sigma”, “pg_sigma”, “prior_alpha” “pg_alpha”. row represents set priors spatio-temporal correlation parameter. Now fit BHM data separately set priors. First, create wrapper function INLA inference prediction. Now fit model separately set prior values. model outputs four models provided tutorial data package ’ll load now. NOTE: ’ve run full models don’t need load files .","code":"priors_dat <- base::data.frame(   prior_range = rep(NA, 4),   ps_range = rep(NA, 4),   prior_sigma = rep(NA, 4),   pg_sigma = rep(NA, 4),   prior_alpha = rep(NA, 4),   pg_alpha = rep(NA, 4) ) priors_dat$prior_range <- c(0.05, 0.1, 0.5, 1) priors_dat$ps_range <- c(0.1, 0.7, 0.9, 0.1)  priors_dat$prior_sigma <- c(0.05, 0.1, 0.5, 2) priors_dat$pg_sigma <- c(0.2, 0.4, 0.5, 0.7)  priors_dat$prior_alpha <- c(-0.2, 0.1, 0.4, 0.8) priors_dat$pg_alpha <- c(0.8, 0.7, 0.6, 0.5) INLA_infer <- function(mesh, prior_range, ps_range,                        prior_sigma, pg_sigma,                        prior_ar1, pg_ar1,                        data) {   spde <- INLA::inla.spde2.pcmatern(     mesh = mesh,     prior.range = c(prior_range, ps_range),     prior.sigma = c(prior_sigma, pg_sigma)   )    alphaprior <- base::list(theta = list(     prior = \"pccor1\",     param = c(prior_ar1, pg_ar1)   ))     group_index <- data$week   n_groups <- base::length(base::unique(data$week))   sp::coordinates(data) <- c(\"LONG\", \"LAT\")    formula <- cases ~ 0 + Intercept + f(     main = coordinates,     model = spde,     group = group_index,     ngroup = n_groups,     control.group = list(       model = \"ar1\",       hyper = alphaprior     )   )    inlabru_model <- inlabru::bru(formula,     data = data,     family = \"poisson\",     E = data$Population,     control.family = list(link = \"log\"),     options = list(       verbose = FALSE     )   )    fitted.mean.post <- inlabru_model$summary.fitted.values$mean[1:nrow(data)]   fitted.sd.post <- inlabru_model$summary.fitted.values$mean[1:nrow(data)]    mean.post <- inlabru_model$summary.random$f$mean   sd.post <- inlabru_model$summary.random$f$sd   fixed.mean <- inlabru_model$summary.fixed$mean   dic <- inlabru_model$dic$dic   pars <- inlabru_model$marginals.hyperpar    return(list(     fitted.mean.post = fitted.mean.post,     fitted.sd.post = fitted.sd.post,     mean.post = mean.post,     sd.post = sd.post,     fixed.mean = fixed.mean,     dic = dic,     pars = pars   )) } m1 <- INLA_infer(   mesh = mesh,   prior_range = priors_dat$prior_range[1],   ps_range = priors_dat$ps_range[1],   prior_sigma = priors_dat$prior_sigma[1],   pg_sigma = priors_dat$pg_sigma[1],   prior_ar1 = priors_dat$prior_alpha[1],   pg_ar1 = priors_dat$pg_alpha[1],   data = covid19_data )  m2 <- INLA_infer(   mesh = mesh,   prior_range = priors_dat$prior_range[2],   ps_range = priors_dat$ps_range[2],   prior_sigma = priors_dat$prior_sigma[2],   pg_sigma = priors_dat$pg_sigma[2],   prior_ar1 = priors_dat$prior_alpha[2],   pg_ar1 = priors_dat$pg_alpha[2],   data = covid19_data )  m3 <- INLA_infer(   mesh = mesh,   prior_range = priors_dat$prior_range[3],   ps_range = priors_dat$ps_range[3],   prior_sigma = priors_dat$prior_sigma[3],   pg_sigma = priors_dat$pg_sigma[3],   prior_ar1 = priors_dat$prior_alpha[3],   pg_ar1 = priors_dat$pg_alpha[3],   data = covid19_data )  m4 <- INLA_infer(   mesh = mesh,   prior_range = priors_dat$prior_range[4],   ps_range = priors_dat$ps_range[4],   prior_sigma = priors_dat$prior_sigma[4],   pg_sigma = priors_dat$pg_sigma[4],   prior_ar1 = priors_dat$prior_alpha[4],   pg_ar1 = priors_dat$pg_alpha[4],   data = covid19_data ) m1 <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"m1.rds\") m2 <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"m2.rds\") m3 <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"m3.rds\") m4 <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"m4.rds\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"compare-the-posteriors-of-the-parameters-for-different-priors-","dir":"Articles","previous_headings":"","what":"Compare the posteriors of the parameters for different priors.","title":"Priors exploration","text":"Different prior values result different model parameter estimates.","code":"plot(m1$pars$`Range for f`,   type = \"l\",   main = \"range\", xlim = c(0.06, 0.3), col = 1 ) lines(m2$pars$`Range for f`, col = 2) lines(m3$pars$`Range for f`, col = 3) lines(m4$pars$`Range for f`, col = 4) legend(\"topright\", legend = c(\"set1\", \"set2\", \"set3\", \"set4\"), lty = rep(1, 4), col = c(1, 2, 3, 4)) plot(m1$pars$`Stdev for f`,   type = \"l\",   main = \"marginal standard deviation \", xlim = c(0.3, 1.45), col = 1 ) lines(m2$pars$`Stdev for f`, col = 2) lines(m3$pars$`Stdev for f`, col = 3) lines(m4$pars$`Stdev for f`, col = 4) legend(\"topright\", legend = c(\"set1\", \"set2\", \"set3\", \"set4\"), lty = rep(1, 4), col = c(1, 2, 3, 4)) plot(m1$pars$`GroupRho for f`,   type = \"l\",   main = \"AR(1) \", xlim = c(0.7, 0.99), ylim = c(0, 21), col = 1 ) lines(m2$pars$`GroupRho for f`, col = 2) lines(m3$pars$`GroupRho for f`, col = 3) lines(m4$pars$`GroupRho for f`, col = 4) legend(\"topright\", legend = c(\"set1\", \"set2\", \"set3\", \"set4\"), lty = rep(1, 4), col = c(1, 2, 3, 4))"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"compare-the-posterior-estimates-of-covid-19-infection-rates-for-different-priors","dir":"Articles","previous_headings":"","what":"Compare the posterior estimates of COVID-19 infection rates for different priors","title":"Priors exploration","text":"boxplots density curves estimated COVID-19 infection rates model shown . Although priors different, posterior infection rate estimates among four models similar, indicating modelling results robust choice priors.","code":"post_rate <- base::cbind.data.frame(   \"set1\" = m1$fitted.mean.post,   \"set2\" = m2$fitted.mean.post,   \"set3\" = m3$fitted.mean.post,   \"set4\" = m4$fitted.mean.post ) graphics::boxplot(post_rate, xlab = \"Prior scenario\", ylab = \"Rate estimates\") post_rate <- base::cbind.data.frame(   \"Prior scenario\" = rep(c(\"set1\", \"set2\", \"set3\", \"set4\"), each = nrow(covid19_data)),   \"Rate estimates\" = c(     m1$fitted.mean.post, m2$fitted.mean.post,     m3$fitted.mean.post, m4$fitted.mean.post   ) )  ggplot2::ggplot(post_rate, ggplot2::aes(x = `Rate estimates`, color = `Prior scenario`)) +   ggplot2::geom_density()"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"compare-the-observed-rates-and-the-estimated-rates-for-different-priors-","dir":"Articles","previous_headings":"","what":"Compare the observed rates and the estimated rates for different priors.","title":"Priors exploration","text":"compare distribution estimated infection rates observed rates different priors.","code":"pos_obs_rate <- base::rbind.data.frame(   data.frame(     \"scenario\" = post_rate[post_rate$`Prior scenario` == \"set1\", ]$`Prior scenario`,     \"rate\" = post_rate[post_rate$`Prior scenario` == \"set1\", ]$`Rate estimates`   ),   base::cbind.data.frame(\"scenario\" = base::rep(\"observed\", base::nrow(covid19_data)), \"rate\" = covid19_data$prevalence) ) p1 <- ggplot2::ggplot(pos_obs_rate, ggplot2::aes(x = rate, fill = scenario)) +   ggplot2::geom_histogram(ggplot2::aes(y = ..density..), alpha = 0.3, position = \"identity\")  pos_obs_rate <- base::rbind.data.frame(   data.frame(     \"scenario\" = post_rate[post_rate$`Prior scenario` == \"set2\", ]$`Prior scenario`,     \"rate\" = post_rate[post_rate$`Prior scenario` == \"set2\", ]$`Rate estimates`   ),   base::cbind.data.frame(\"scenario\" = base::rep(\"observed\", base::nrow(covid19_data)), \"rate\" = covid19_data$prevalence) ) p2 <- ggplot2::ggplot(pos_obs_rate, ggplot2::aes(x = rate, fill = scenario)) +   ggplot2::geom_histogram(ggplot2::aes(y = ..density..), alpha = 0.3, position = \"identity\")  pos_obs_rate <- base::rbind.data.frame(   data.frame(     \"scenario\" = post_rate[post_rate$`Prior scenario` == \"set3\", ]$`Prior scenario`,     \"rate\" = post_rate[post_rate$`Prior scenario` == \"set3\", ]$`Rate estimates`   ),   base::cbind.data.frame(\"scenario\" = base::rep(\"observed\", base::nrow(covid19_data)), \"rate\" = covid19_data$prevalence) ) p3 <- ggplot2::ggplot(pos_obs_rate, ggplot2::aes(x = rate, fill = scenario)) +   ggplot2::geom_histogram(ggplot2::aes(y = ..density..), alpha = 0.3, position = \"identity\")   pos_obs_rate <- base::rbind.data.frame(   data.frame(     \"scenario\" = post_rate[post_rate$`Prior scenario` == \"set4\", ]$`Prior scenario`,     \"rate\" = post_rate[post_rate$`Prior scenario` == \"set4\", ]$`Rate estimates`   ),   base::cbind.data.frame(\"scenario\" = base::rep(\"observed\", base::nrow(covid19_data)), \"rate\" = covid19_data$prevalence) ) p4 <- ggplot2::ggplot(pos_obs_rate, ggplot2::aes(x = rate, fill = scenario)) +   ggplot2::geom_histogram(ggplot2::aes(y = ..density..), alpha = 0.3, position = \"identity\")  gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"compare-the-predicted-mean-fields-for-different-priors","dir":"Articles","previous_headings":"","what":"Compare the predicted mean fields for different priors","title":"Priors exploration","text":"compare predicted mean Gaussian random field.","code":"mod.proj <- INLA::inla.mesh.projector(mesh) xygrid <- base::expand.grid(mod.proj$x, mod.proj$y) Aproj <- INLA::inla.spde.make.A(mesh = mesh, loc = as.matrix(xygrid)) z <- base::exp(base::as.numeric(Aproj %*% m1$mean.post[1:mesh$n]) +   base::sum(m1$summary.fixed$mean))  predfield <- base::data.frame(x = xygrid[, 1], y = xygrid[, 2], z = z)  g1 <- ggplot2::ggplot(predfield) +   ggplot2::coord_fixed() +   ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = z)) +   ggplot2::scale_fill_gradientn(colours = terrain.colors(12), limit = c(0.9, 2.33)) +   ggplot2::ggtitle(\"Set1\")   z <- base::exp(base::as.numeric(Aproj %*% m2$mean.post[1:mesh$n]) +   base::sum(m2$summary.fixed$mean)) predfield <- base::data.frame(x = xygrid[, 1], y = xygrid[, 2], z = z) g2 <- ggplot2::ggplot(predfield) +   ggplot2::coord_fixed() +   ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = z)) +   ggplot2::scale_fill_gradientn(colours = terrain.colors(12), limit = c(0.9, 2.33)) +   ggplot2::ggtitle(\"Set2\")  z <- base::exp(base::as.numeric(Aproj %*% m3$mean.post[1:mesh$n]) +   base::sum(m3$summary.fixed$mean)) predfield <- base::data.frame(x = xygrid[, 1], y = xygrid[, 2], z = z) g3 <- ggplot2::ggplot(predfield) +   ggplot2::coord_fixed() +   ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = z)) +   ggplot2::scale_fill_gradientn(colours = terrain.colors(12), limit = c(0.9, 2.33)) +   ggplot2::ggtitle(\"Set3\")  z <- base::exp(base::as.numeric(Aproj %*% m4$mean.post[1:mesh$n]) +   base::sum(m4$summary.fixed$mean))  predfield <- base::data.frame(x = xygrid[, 1], y = xygrid[, 2], z = z) g4 <- ggplot2::ggplot(predfield) +   ggplot2::coord_fixed() +   ggplot2::geom_raster(ggplot2::aes(x = x, y = y, fill = z)) +   ggplot2::scale_fill_gradientn(colours = terrain.colors(12), limit = c(0.9, 2.33)) +   ggplot2::ggtitle(\"Set4\")  gridExtra::grid.arrange(g1, g2, g3, g4, ncol = 2)"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"compare-the-information-criterion-values-for-different-priors","dir":"Articles","previous_headings":"","what":"Compare the information criterion values for different priors","title":"Priors exploration","text":"Finally, compare Deviance Information Criterion values four models. model second set priors better model fit others smallest DIC value.","code":"infocri <- base::cbind.data.frame(   priors = c(\"set1\", \"set2\", \"set3\", \"set4\"),   DIC = c(m1$dic, m2$dic, m3$dic, m4$dic) )  infocri$priors <- base::as.factor(infocri$priors)  ggplot2::ggplot(infocri, ggplot2::aes(x = priors, y = DIC)) +   ggplot2::geom_point()"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"influence-of-inappropriate-priors-on-model-inference","dir":"Articles","previous_headings":"","what":"Influence of inappropriate priors on model inference","title":"Priors exploration","text":"Bayesian inference influenced priors data. Therefore, choosing appropriate prior crucial making sensible inferences parameters. Now demonstrate inappropriate priors can impact model inference. four models mentioned , priors \\(\\rho\\), \\(\\sigma\\) \\(\\alpha\\) specified using probabilistic statements. Now consider extreme scenario priors set way parameters \\(\\rho\\) \\(\\sigma\\) take fixed values. achieved setting ps_range pg_sigma NA, prior_range prior_sigma used enforce fixed parameter values. NOTE: ’ve run model don’t need load file . Now compare distribution predicted rates models m1, m2, m3, m4 m5.  figure indicates models m1, m2, m3, m4 demonstrate high degree agreement observed infection rates (denoted obs) predictions. Conversely, model m5 exhibits significant discrepancies, predictions deviating substantially observed data. compare DIC values find model m5 produces highest DIC value, indicating exhibits poorer model fit compared models.  use inappropriate priors leads inaccurate predictions can also cause INLA crash model fitting. instance, assign prior P(\\(\\alpha\\) > 0) = 0.3 \\(\\alpha\\), suggests probability \\(\\alpha\\) greater 0 0.3, assign set4 priors parameters, INLA program encounter errors trying fit model. Model m6 encounters errors execution: *** inla.core.safe: inla.program crashed.*** Fail get good enough initial values. highlights importance specifying appropriate priors model parameters, directly impacts model performance. Choosing suitable priors can help avoid issues like convergence problems ensure stability accuracy model fitting process.","code":"prior_range <- 0.1 ps_range <- NA prior_sigma <- 0.01 pg_sigma <- NA  m5 <- INLA_infer(   mesh = mesh,   prior_range = prior_range,   ps_range = ps_range,   prior_sigma = prior_sigma,   pg_sigma = pg_sigma,   prior_ar1 = priors_dat$prior_alpha[4],   pg_ar1 = priors_dat$pg_alpha[4],   data = covid19_data ) m5 <- fdmr::load_tutorial_data(dataset = \"priors\", filename = \"m5.rds\") post_rate <- base::cbind.data.frame(   \"model\" = base::rep(c(\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"obs\"),     each = base::nrow(covid19_data)   ),   \"Infection rate\" = c(     m1$fitted.mean.post, m2$fitted.mean.post,     m3$fitted.mean.post, m4$fitted.mean.post,     m5$fitted.mean.post,     covid19_data$prevalence   ) ) ggplot2::ggplot(post_rate, ggplot2::aes(x = `Infection rate`, color = `model`)) +   ggplot2::geom_density() +   ggplot2::theme(legend.title = ggplot2::element_blank()) infocri <- base::cbind.data.frame(   priors = c(\"m1\", \"m2\", \"m3\", \"m4\", \"m5\"),   DIC = c(m1$dic, m2$dic, m3$dic, m4$dic, m5$dic) ) infocri$priors <- base::as.factor(infocri$priors) ggplot2::ggplot(infocri, ggplot2::aes(x = priors, y = DIC)) +   ggplot2::geom_point() m6 <- INLA_infer(   mesh = mesh,   prior_range = priors_dat$prior_range[4],   ps_range = priors_dat$ps_range[4],   prior_sigma = priors_dat$prior_sigma[4],   pg_sigma = priors_dat$pg_sigma[4],   prior_ar1 = 0,   pg_ar1 = 0.3,   data = covid19_data )"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors.html","id":"shiny-app","dir":"Articles","previous_headings":"Influence of inappropriate priors on model inference","what":"Shiny app","title":"Priors exploration","text":"investigate settings priors interactively ’ve created Shiny app allows priors changed outcomes plotted. ’ll use data loaded initial values priors plot model ouput within app. ’ll create mesh pass app.","code":"initial_range <- diff(base::range(sp_data@data[, \"LONG\"])) / 3 max_edge <- initial_range / 2  mesh <- INLA::inla.mesh.2d(   loc = sp_data@data[, c(\"LONG\", \"LAT\")],   max.edge = c(1, 2) * max_edge,   offset = c(initial_range, initial_range),   cutoff = max_edge / 7 ) fdmr::interactive_priors(spatial_data=sp_data, measurement_data = covid19_data, mesh=mesh)"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors_app.html","id":"create-the-mesh","dir":"Articles","previous_headings":"","what":"Create the mesh","title":"Interactive priors Shiny app","text":"can look mesh change interactively using mesh_builder Shiny app. Using app came mesh following parameters, ’ll use pass Setting Priors Shiny app . order fit model, also need define temporal index (must integer starting 1) number discrete time points want model.","code":"initial_range <- diff(base::range(sp_data@data[, \"LONG\"])) / 3 max_edge <- initial_range / 2 mesh <- INLA::inla.mesh.2d(   loc = sp_data@data[, c(\"LONG\", \"LAT\")],   max.edge = c(1, 2) * max_edge,   offset = c(initial_range, initial_range),   cutoff = max_edge / 7 ) group_index <- covid19_data$week n_groups <- length(unique(covid19_data$week))"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors_app.html","id":"set-coordinates-on-data","dir":"Articles","previous_headings":"","what":"Set coordinates on data","title":"Interactive priors Shiny app","text":"use function bru() package inlabru fit model. bru expects coordinates data, thus transform covid19_data_bris data set SpatialPointsDataFrame using function coordinates() sp package.","code":"sp::coordinates(covid19_data) <- c(\"LONG\", \"LAT\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors_app.html","id":"use-the-interactive-priors-shiny-app","dir":"Articles","previous_headings":"","what":"Use the Interactive Priors Shiny app","title":"Interactive priors Shiny app","text":"Now filtered data ready pass spatial First start selecting variable model. example ’ll select cases, select features add formula. bottom window ’ll see formula constructed. Click checkboxes select formula click Run Model button run model see ’s output plot right window.","code":"fdmr::interactive_priors(spatial_data = sp_data, measurement_data = covid19_data, mesh=mesh, time_variable=\"week\")"},{"path":"https://4dmodeller.github.io/fdmr/articles/priors_app.html","id":"viewing-model-outputs-and-parameter-sets","dir":"Articles","previous_headings":"","what":"Viewing model outputs and parameter sets","title":"Interactive priors Shiny app","text":"outputs model run app can viewed fdmr/logs folder home directory. ’ll find three log files priors_exploration_applog_timestamp.txt - holds general logging information errors priors_exploration_parameters_timestamp.json - holds priors used model run priors_exploration_modelout_timestamp.rds - holds model output run","code":""},{"path":"https://4dmodeller.github.io/fdmr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gareth Jones. Author, maintainer. Xueqing Yin. Author. John Aiken. Author. Jonathan Bamber. Author.","code":""},{"path":"https://4dmodeller.github.io/fdmr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jones G, Yin X, Aiken J, Bamber J (2023). fdmr: 4D Modeller project. R package version 0.0.1, https://github.com/4DModeller/fdmr.","code":"@Manual{,   title = {fdmr: 4D Modeller project},   author = {Gareth Jones and Xueqing Yin and John Aiken and Jonathan Bamber},   year = {2023},   note = {R package version 0.0.1},   url = {https://github.com/4DModeller/fdmr}, }"},{"path":"https://4dmodeller.github.io/fdmr/index.html","id":"id_4dmodeller-","dir":"","previous_headings":"","what":"4D Modeller project","title":"4D Modeller project","text":"4D-Modeller spatio-temporal modeling library can applied problems scale micro processes operate global scale. includes data visualization tools, finite element mesh building tools, Bayesian hierarchical modeling based Bayesian inference packages INLA inlabru, model evaluation assessment tools.","code":""},{"path":"https://4dmodeller.github.io/fdmr/index.html","id":"why-should-i-use-4d-modeller","dir":"","previous_headings":"","what":"Why should I use 4d-Modeller?","title":"4D Modeller project","text":"4d-Modeller R toolbox designed make easy design spatially distributed, temporally dependent statistical models. Typically, 4d-Modeller expects tabular data sets spatial coordinates, time indices, values change remain constant times. designed used modeling process data sufficiently organized wherever gathered . 4d-Modeller stack tools include shiny apps, vignettes R-markdown notebooks, library . tools designed help easily build finite element meshes models can calculated : fem tools specify priors model pick best model hyperparameters: priors tools evaluating fully trained model output: eval","code":""},{"path":"https://4dmodeller.github.io/fdmr/index.html","id":"quickstart","dir":"","previous_headings":"","what":"Quickstart","title":"4D Modeller project","text":"get 4DModeller R package fdmr installed first need make sure recent version R installed. easiest way install RStudio. Next start R session run Next need install INLA available CRAN. now fdmr dependencies installed can continue one tutorials.","code":"install.packages(\"devtools\") library(devtools) devtools::install_github(\"4DModeller/fdmr\") install.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE)"},{"path":"https://4dmodeller.github.io/fdmr/reference/clean_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a ~ expanded absolute path — clean_path","title":"Returns a ~ expanded absolute path — clean_path","text":"Returns ~ expanded absolute path","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/clean_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a ~ expanded absolute path — clean_path","text":"","code":"clean_path(path, check_exists = FALSE)"},{"path":"https://4dmodeller.github.io/fdmr/reference/clean_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a ~ expanded absolute path — clean_path","text":"path Path clean check_exists Check path exists, error ","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/clean_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a ~ expanded absolute path — clean_path","text":"fs::path Expanded absolute path","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/clear_caches.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear both tutorial data and downloaded archive caches — clear_caches","title":"Clear both tutorial data and downloaded archive caches — clear_caches","text":"Clear tutorial data downloaded archive caches","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/clear_caches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear both tutorial data and downloaded archive caches — clear_caches","text":"","code":"clear_caches()"},{"path":"https://4dmodeller.github.io/fdmr/reference/get_archive_cache_datapath.html","id":null,"dir":"Reference","previous_headings":"","what":"Get path to downloaded archive cache folder — get_archive_cache_datapath","title":"Get path to downloaded archive cache folder — get_archive_cache_datapath","text":"Get path downloaded archive cache folder","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_archive_cache_datapath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get path to downloaded archive cache folder — get_archive_cache_datapath","text":"","code":"get_archive_cache_datapath()"},{"path":"https://4dmodeller.github.io/fdmr/reference/get_archive_cache_datapath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get path to downloaded archive cache folder — get_archive_cache_datapath","text":"fs::path","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_cache_datapath.html","id":null,"dir":"Reference","previous_headings":"","what":"Get path to tutorial data cache folder — get_tutorial_cache_datapath","title":"Get path to tutorial data cache folder — get_tutorial_cache_datapath","text":"Get path tutorial data cache folder","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_cache_datapath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get path to tutorial data cache folder — get_tutorial_cache_datapath","text":"","code":"get_tutorial_cache_datapath()"},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_cache_datapath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get path to tutorial data cache folder — get_tutorial_cache_datapath","text":"fs::path","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_datapath.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the filepath for a tutorial data file. — get_tutorial_datapath","title":"Return the filepath for a tutorial data file. — get_tutorial_datapath","text":"Return filepath tutorial data file.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_datapath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the filepath for a tutorial data file. — get_tutorial_datapath","text":"","code":"get_tutorial_datapath(dataset, filename)"},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_datapath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the filepath for a tutorial data file. — get_tutorial_datapath","text":"dataset Name dataset filename Name file","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/get_tutorial_datapath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the filepath for a tutorial data file. — get_tutorial_datapath","text":"fs::path Full filepath","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/interactive_priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactively set and see the result of different priors — interactive_priors","title":"Interactively set and see the result of different priors — interactive_priors","text":"Interactively set see result different priors","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/interactive_priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactively set and see the result of different priors — interactive_priors","text":"","code":"interactive_priors(spatial_data, measurement_data, time_variable, mesh)"},{"path":"https://4dmodeller.github.io/fdmr/reference/interactive_priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactively set and see the result of different priors — interactive_priors","text":"spatial_data Spatial data measurement_data Measurement data time_variable Time variable measurement_data mesh INLA mesh","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/interactive_priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interactively set and see the result of different priors — interactive_priors","text":"shiny::app","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/latlong_to_utm.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert latitude and longitude to UTM coordinates — latlong_to_utm","title":"Convert latitude and longitude to UTM coordinates — latlong_to_utm","text":"Convert latitude longitude UTM coordinates","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/latlong_to_utm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert latitude and longitude to UTM coordinates — latlong_to_utm","text":"","code":"latlong_to_utm(lat, lon)"},{"path":"https://4dmodeller.github.io/fdmr/reference/latlong_to_utm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert latitude and longitude to UTM coordinates — latlong_to_utm","text":"lat Latitude lon Longitude","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/latlong_to_utm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert latitude and longitude to UTM coordinates — latlong_to_utm","text":"vector UTM coordinates","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/load_tutorial_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load data from the tutorial data store — load_tutorial_data","title":"Load data from the tutorial data store — load_tutorial_data","text":"Load data tutorial data store","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/load_tutorial_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load data from the tutorial data store — load_tutorial_data","text":"","code":"load_tutorial_data(dataset, filename)"},{"path":"https://4dmodeller.github.io/fdmr/reference/load_tutorial_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load data from the tutorial data store — load_tutorial_data","text":"dataset Name dataset filename Name file","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/load_tutorial_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load data from the tutorial data store — load_tutorial_data","text":"loaded object","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_builder.html","id":null,"dir":"Reference","previous_headings":"","what":"Mesh building shiny app. Creates and visualises a mesh from some spatial data. — mesh_builder","title":"Mesh building shiny app. Creates and visualises a mesh from some spatial data. — mesh_builder","text":"Mesh building shiny app. Creates visualises mesh spatial data.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_builder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mesh building shiny app. Creates and visualises a mesh from some spatial data. — mesh_builder","text":"","code":"mesh_builder(   spatial_data,   obs_data = NULL,   crs = NULL,   max_edge = NULL,   offset = NULL,   cutoff = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_builder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mesh building shiny app. Creates and visualises a mesh from some spatial data. — mesh_builder","text":"spatial_data Spatial data obs_data Measurement data crs CRS proj4string max_edge largest allowed triangle edge length. One two values, passed inla.mesh.2d offset Specifies size inner outer extensions around data locations, passed inla.mesh.2d cutoff minimum allowed distance points, passed inla.mesh.2d","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_builder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mesh building shiny app. Creates and visualises a mesh from some spatial data. — mesh_builder","text":"shiny::app","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_checker.html","id":null,"dir":"Reference","previous_headings":"","what":"Check a mesh for errors:\n\nA greater number of mesh nodes than observations\nA greater number of mesh triangles than observations\nIsolated triangles in mesh\n — mesh_checker","title":"Check a mesh for errors:\n\nA greater number of mesh nodes than observations\nA greater number of mesh triangles than observations\nIsolated triangles in mesh\n — mesh_checker","text":"Check mesh errors: greater number mesh nodes observations greater number mesh triangles observations Isolated triangles mesh","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_checker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check a mesh for errors:\n\nA greater number of mesh nodes than observations\nA greater number of mesh triangles than observations\nIsolated triangles in mesh\n — mesh_checker","text":"","code":"mesh_checker(mesh, observations)"},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_checker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check a mesh for errors:\n\nA greater number of mesh nodes than observations\nA greater number of mesh triangles than observations\nIsolated triangles in mesh\n — mesh_checker","text":"mesh INLA mesh observations Observations data used woith model","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_checker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check a mesh for errors:\n\nA greater number of mesh nodes than observations\nA greater number of mesh triangles than observations\nIsolated triangles in mesh\n — mesh_checker","text":"list: Named list containing errors","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_to_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an INLA mesh to a SpatialPolygonsDataFrame — mesh_to_spatial","title":"Convert an INLA mesh to a SpatialPolygonsDataFrame — mesh_to_spatial","text":"Convert INLA mesh SpatialPolygonsDataFrame","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_to_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an INLA mesh to a SpatialPolygonsDataFrame — mesh_to_spatial","text":"","code":"mesh_to_spatial(mesh, crs = NULL)"},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_to_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an INLA mesh to a SpatialPolygonsDataFrame — mesh_to_spatial","text":"mesh Mesh crs Coordinate Reference System proj4 format. Required mesh CRS defined.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/mesh_to_spatial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an INLA mesh to a SpatialPolygonsDataFrame — mesh_to_spatial","text":"SpatialPolygonsDataFrame","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/meshbuilder_shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Mesh building shiny app — meshbuilder_shiny","title":"Mesh building shiny app — meshbuilder_shiny","text":"Mesh building shiny app","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/meshbuilder_shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mesh building shiny app — meshbuilder_shiny","text":"","code":"meshbuilder_shiny(   spatial_data,   obs_data = NULL,   crs = NULL,   max_edge = NULL,   offset = NULL,   cutoff = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/meshbuilder_shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mesh building shiny app — meshbuilder_shiny","text":"spatial_data Spatial data crs CRS proj4string max_edge largest allowed triangle edge length. One two values, passed inla.mesh.2d offset Specifies size inner outer extensions around data locations, passed inla.mesh.2d cutoff minimum allowed distance points, passed inla.mesh.2d data Observations data, use check_mesh functionality","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/meshbuilder_shiny.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mesh building shiny app — meshbuilder_shiny","text":"shiny::app","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/numbers_only.html","id":null,"dir":"Reference","previous_headings":"","what":"Removes any character that isn't a letter — numbers_only","title":"Removes any character that isn't a letter — numbers_only","text":"Removes character letter","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/numbers_only.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Removes any character that isn't a letter — numbers_only","text":"","code":"numbers_only(data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/numbers_only.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Removes any character that isn't a letter — numbers_only","text":"data String data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/numbers_only.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Removes any character that isn't a letter — numbers_only","text":"string data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse model output to create a list of model parameters — parse_model_output","title":"Parse model output to create a list of model parameters — parse_model_output","text":"Parse model output create list model parameters","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse model output to create a list of model parameters — parse_model_output","text":"","code":"parse_model_output(model_output, measurement_data, model_type = \"inlabru\")"},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse model output to create a list of model parameters — parse_model_output","text":"model_output Data returned model measurement_data Measurement data model_type Type model, currently support inlabru","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse model output to create a list of model parameters — parse_model_output","text":"list","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output_bru.html","id":null,"dir":"Reference","previous_headings":"","what":"Parses inlabru::bru model output to create a list of model parameters — parse_model_output_bru","title":"Parses inlabru::bru model output to create a list of model parameters — parse_model_output_bru","text":"Parses inlabru::bru model output create list model parameters","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output_bru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parses inlabru::bru model output to create a list of model parameters — parse_model_output_bru","text":"","code":"parse_model_output_bru(model_output, measurement_data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output_bru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parses inlabru::bru model output to create a list of model parameters — parse_model_output_bru","text":"model_output Output running inlabru::bru measurement_data Measurement data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/parse_model_output_bru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parses inlabru::bru model output to create a list of model parameters — parse_model_output_bru","text":"list","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_ar1.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot AR(1) — plot_ar1","title":"Plot AR(1) — plot_ar1","text":"Plot AR(1)","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_ar1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot AR(1) — plot_ar1","text":"","code":"plot_ar1(data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_ar1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot AR(1) — plot_ar1","text":"data Parsed model output to_plot Type data plot, \"Range f\" etc","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_ar1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot AR(1) — plot_ar1","text":"ggplot2::ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_barchart.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a bar chart using ggplot2 — plot_barchart","title":"Plot a bar chart using ggplot2 — plot_barchart","text":"Plot bar chart using ggplot2","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_barchart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a bar chart using ggplot2 — plot_barchart","text":"","code":"plot_barchart(   data,   x,   y,   breaks,   x_label,   y_label,   fill = \"pink\",   colour = \"blue\" )"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_barchart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a bar chart using ggplot2 — plot_barchart","text":"data Data plot x x-axis data y y-axis data breaks Break points x_label x-axis label y_label y-axis label fill Fill colour colour Line colour","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_barchart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a bar chart using ggplot2 — plot_barchart","text":"ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_boxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a boxplot using ggplot2 — plot_boxplot","title":"Plot a boxplot using ggplot2 — plot_boxplot","text":"Plot boxplot using ggplot2","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_boxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a boxplot using ggplot2 — plot_boxplot","text":"","code":"plot_boxplot(data, x, y, breaks, x_label, y_label)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_boxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a boxplot using ggplot2 — plot_boxplot","text":"data Data plot x x-axis data y y-axis data breaks Break points x_label x-axis label y_label y-axis label","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_boxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a boxplot using ggplot2 — plot_boxplot","text":"ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_dic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Deviance Information Criterion (DIC) values — plot_dic","title":"Plot Deviance Information Criterion (DIC) values — plot_dic","text":"Plot Deviance Information Criterion (DIC) values","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_dic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Deviance Information Criterion (DIC) values — plot_dic","text":"","code":"plot_dic(data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_dic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Deviance Information Criterion (DIC) values — plot_dic","text":"data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_dic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Deviance Information Criterion (DIC) values — plot_dic","text":"ggplot2::ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_interactive_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the Shiny app for plotting raster and polygon data on a leaflet map. — plot_interactive_map","title":"Run the Shiny app for plotting raster and polygon data on a leaflet map. — plot_interactive_map","text":"Run Shiny app plotting raster polygon data leaflet map.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_interactive_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the Shiny app for plotting raster and polygon data on a leaflet map. — plot_interactive_map","text":"","code":"plot_interactive_map(   raster_data = NULL,   polygon_data = NULL,   date_format = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_interactive_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the Shiny app for plotting raster and polygon data on a leaflet map. — plot_interactive_map","text":"raster_data Raster data form RasterStack RasterBrick polygon_data Polygon data plot map date_format date format passed lubridate::as_date","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_interactive_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the Shiny app for plotting raster and polygon data on a leaflet map. — plot_interactive_map","text":"shinyApp","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a line plot with a confidence interval. — plot_line_average","title":"Create a line plot with a confidence interval. — plot_line_average","text":"Create line plot confidence interval.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a line plot with a confidence interval. — plot_line_average","text":"","code":"plot_line_average(   data,   x,   y1,   y2,   y3,   breaks,   x_label,   y_label,   y1_colour = \"blue\",   y2_colour = \"red\",   y3_colour = \"red\",   x_lim = NULL,   y_lim = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a line plot with a confidence interval. — plot_line_average","text":"data Data plot x x-axis data y1 y1 line data - solid y2 y2 line data - dashed y3 y3 line data - dashed breaks Breaks vector x_label x-axis label y_label y-axis label y1_colour Colour y1 y2_colour Colour y2 y3_colour Colour y3 x_lim x-axis limits vector e.g. c(0, 0.1) y_lim y-axis limits vector e.g. c(0, 1.0)","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a line plot with a confidence interval. — plot_line_average","text":"ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot line comparison for stdev etc — plot_line_comparison","title":"Plot line comparison for stdev etc — plot_line_comparison","text":"Plot line comparison stdev etc","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot line comparison for stdev etc — plot_line_comparison","text":"","code":"plot_line_comparison(data, to_plot, title)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot line comparison for stdev etc — plot_line_comparison","text":"data Parsed model output to_plot Type data plot, \"Range f\" etc","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_line_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot line comparison for stdev etc — plot_line_comparison","text":"ggplot2::ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a simple Leaflet map from data — plot_map","title":"Create a simple Leaflet map from data — plot_map","text":"Create simple Leaflet map data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a simple Leaflet map from data — plot_map","text":"","code":"plot_map(   polygon_data = NULL,   raster_data = NULL,   domain = NULL,   markers = NULL,   palette = \"viridis\",   legend_title = NULL,   add_scale_bar = FALSE,   polygon_fill_colour = \"#E4572E\",   polygon_line_colour = \"grey\",   polygon_line_weight = 1,   polygon_fill_opacity = 0.6 )"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a simple Leaflet map from data — plot_map","text":"polygon_data Polygon data raster_data Raster datas domain Domain data passed leaflet::colorNumeric leaflet::addLegend markers Markers display map. named list latitude, longitude label names must given. palette Palette used colours, defaults viridis legend_title Title legend add_scale_bar Add scale bar TRUE polygon_fill_colour Polygon fill colour polygon_line_colour Polygon surrounding line colour polygon_line_weight Polygon surrounding line weight polygon_fill_opacity Leaflet polygon fill opacity, float 0 1.0, passed fillOpacity leaflet::addPolygons","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a simple Leaflet map from data — plot_map","text":"leaflet::leaflet","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_mesh.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a mesh — plot_mesh","title":"Plot a mesh — plot_mesh","text":"Plot mesh","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_mesh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a mesh — plot_mesh","text":"","code":"plot_mesh(mesh, point_data, point_colour = \"blue\", cex = 0.1)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_mesh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a mesh — plot_mesh","text":"mesh Mesh data point_data Points data point_colour Colour points cex Point size magnifier","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_boxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create boxplots from priors run data — plot_priors_boxplot","title":"Create boxplots from priors run data — plot_priors_boxplot","text":"Create boxplots priors run data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_boxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create boxplots from priors run data — plot_priors_boxplot","text":"","code":"plot_priors_boxplot(data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_boxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create boxplots from priors run data — plot_priors_boxplot","text":"data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_boxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create boxplots from priors run data — plot_priors_boxplot","text":"graphics::boxplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot density function — plot_priors_density","title":"Plot density function — plot_priors_density","text":"Plot density function","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot density function — plot_priors_density","text":"","code":"plot_priors_density(data, measurement_data)"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot density function — plot_priors_density","text":"data Parsed model outputs measurement_data Measurement data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_priors_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot density function — plot_priors_density","text":"ggplot2::ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot timeseries data — plot_timeseries","title":"Plot timeseries data — plot_timeseries","text":"Plot timeseries data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot timeseries data — plot_timeseries","text":"","code":"plot_timeseries(   data,   x,   y,   breaks = NULL,   x_label = NULL,   y_label = NULL,   title = NULL,   line_colour = \"blue\",   horizontal_y = NULL,   vertical_x = NULL,   x_lim = NULL,   y_lim = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_timeseries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot timeseries data — plot_timeseries","text":"data Data plot x Name column plot x-axis, datetime, converted Dates using .Date y Name column plot y-axis breaks Date break points x_label x-axis label y_label y-axis label title Figure title line_colour Line colour horizontal_y y-intercept horizontal line vertical_x x-intercept vertical line x_lim Limits x-axis continous scale, vector passed scale_x_continuous y_lim Limits y-axis continuous scale, vector passed scale_y_continous line_width Line width","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/plot_timeseries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot timeseries data — plot_timeseries","text":"ggplot","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/priors_shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactively set and see the result of different priors — priors_shiny","title":"Interactively set and see the result of different priors — priors_shiny","text":"Interactively set see result different priors","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/priors_shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactively set and see the result of different priors — priors_shiny","text":"","code":"priors_shiny(spatial_data, measurement_data, time_variable, mesh)"},{"path":"https://4dmodeller.github.io/fdmr/reference/priors_shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactively set and see the result of different priors — priors_shiny","text":"spatial_data Spatial data measurement_data Measurement data time_variable Time variable measurement_data mesh INLA mesh","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/priors_shiny.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interactively set and see the result of different priors — priors_shiny","text":"shiny::app","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/raster_mapping_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny app for plotting raster and polygon data on a leaflet map. — raster_mapping_app","title":"Shiny app for plotting raster and polygon data on a leaflet map. — raster_mapping_app","text":"Shiny app plotting raster polygon data leaflet map.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/raster_mapping_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny app for plotting raster and polygon data on a leaflet map. — raster_mapping_app","text":"","code":"raster_mapping_app(   raster_data = NULL,   polygon_data = NULL,   date_format = NULL,   palette = NULL )"},{"path":"https://4dmodeller.github.io/fdmr/reference/raster_mapping_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny app for plotting raster and polygon data on a leaflet map. — raster_mapping_app","text":"raster_data Raster data form RasterStack RasterBrick polygon_data Polygon data plot map date_format date format passed lubridate::as_date palette Colour palette use","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/raster_mapping_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shiny app for plotting raster and polygon data on a leaflet map. — raster_mapping_app","text":"shinyApp","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/require_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if packages are installed. — require_packages","title":"Checks if packages are installed. — require_packages","text":"Checks packages installed.","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/require_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if packages are installed. — require_packages","text":"","code":"require_packages(packages)"},{"path":"https://4dmodeller.github.io/fdmr/reference/require_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if packages are installed. — require_packages","text":"packages Package name","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/retrieve_tutorial_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve a tutorial dataset and unpacks it to ~/fdmr/tutorial_data — retrieve_tutorial_data","title":"Retrieve a tutorial dataset and unpacks it to ~/fdmr/tutorial_data — retrieve_tutorial_data","text":"Retrieve tutorial dataset unpacks ~/fdmr/tutorial_data","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/retrieve_tutorial_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve a tutorial dataset and unpacks it to ~/fdmr/tutorial_data — retrieve_tutorial_data","text":"","code":"retrieve_tutorial_data(dataset, force_update = FALSE)"},{"path":"https://4dmodeller.github.io/fdmr/reference/retrieve_tutorial_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve a tutorial dataset and unpacks it to ~/fdmr/tutorial_data — retrieve_tutorial_data","text":"dataset Name dataset retrieve force_update Force retrieval metadata dataset","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/to_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert vector of date strings to Date objects — to_dates","title":"Convert vector of date strings to Date objects — to_dates","text":"Convert vector date strings Date objects","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/to_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert vector of date strings to Date objects — to_dates","text":"","code":"to_dates(time_data, sort = FALSE, date_format = NULL)"},{"path":"https://4dmodeller.github.io/fdmr/reference/to_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert vector of date strings to Date objects — to_dates","text":"time_data Time data sort sort Sort TRUE date_format Date format pass lubridate::as_date","code":""},{"path":"https://4dmodeller.github.io/fdmr/reference/to_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert vector of date strings to Date objects — to_dates","text":"vector","code":""}]
